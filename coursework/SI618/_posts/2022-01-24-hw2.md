---
layout: single
title: "HW2. More Data Manipulation"
permalink: /coursework/SI618/hw2/
comments: false
author_profile: true
read_time: true
toc: true
toc_label: "Table of Contents"
toc_sticky: true
categories: ["SI618"]
---

**Topics: Data manipulation, EDA(Exploratory Data Analysis)**

--- 

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.patches as mpatches
```

**The total score for this assignment will be 100 points, consisting of:**
- 10 pt: Overall quality of spelling, grammar, punctuation, etc. of written sentences. ([Guide](https://drive.google.com/file/d/1L0P7xJwjUGBvyb49mL3dw1Bt7hzRTiTl/view ))
- 10 pt: Codes are written in [PEP 8](https://www.python.org/dev/peps/pep-0008/) style.
- 80 pt: Homework questions. 

Version 2022.01.24.1.CT

**Background**           
You're a Data Science Consultant for an eCommerce retail company, they've asked you to analyze their sales database. Unfortunately, they did nothing to prepare or clean their data, only exporting their 3 database tables as JSON files. It's up to you to clean their data, analyze it and answer questions to help drive business value!

**The below files have been provided via the URLs shown:**
- invoices.json https://github.com/umsi-data-science/data/raw/main/invoices.json
- items.json https://github.com/umsi-data-science/data/raw/main/items.json
- purchases.json https://github.com/umsi-data-science/data/raw/main/purchases.json

**They provided this data dictionary:**

- **InvoiceNo:** Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction.  
- **StockCode:** Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.  
- **Description:** Product (item) name. Nominal.   
- **Quantity:** The quantities of each product (item) per transaction. Numeric.  
- **InvoiceDate:** Invoice Date and time. Numeric, the day and time when each transaction was generated.  
- **UnitPrice:** Unit price. Numeric, Product price per unit in sterling.  
- **CustomerID:** Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.  
- **Country:** Country name. Nominal, the name of the country where each customer resides.  

**A few notes from the company:**
* If the InvoiceNo starts with the letter 'c', it indicates a cancellation. When conducting this analysis we only want to analyze invoices that were shipped. (ie. not canceled)
* The datasets should be able to be merged, each row in the invoice table corresponds to multiple rows in the purchases table.
* To find out the description or unit cost of an item in the purchase table, the StockCode should be used to match up the product in the items table. 
* They mentioned that they've been having a difficult time lately joining the items and purchases table, maybe there's something wrong with the columns?

**Answer the questions below.**
- Write your Python code that can answer the following questions, 
- and explain **ALL** your answers in plain English. 
- you can use as many code and markdown cells as you need for each question (i.e. don't limit yourself to just one of each if you feel you need more).


```python
MY_UNIQNAME = 'yjwoo'  # replace this with your uniqname
```

## <span style="color:magenta"> Q1. [5 points] Describe the dataset. </span>
1. Load the data. 
1. How many total invoices have been placed?
1. How many unique customers are there?
1. What is the total number of unique items?
1. Are there any columns with null values?
1. Thinking ahead, how do you think you would join the different tables? Please share 2-3 sentences about your approach.

**Load the data**


```python
df_invoice = pd.read_json("https://github.com/umsi-data-science/data/raw/main/invoices.json")
df_invoice.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>12/1/10 8:26</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536366</td>
      <td>12/1/10 8:28</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536367</td>
      <td>12/1/10 8:34</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536368</td>
      <td>12/1/10 8:34</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536369</td>
      <td>12/1/10 8:35</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_item = pd.read_json("https://github.com/umsi-data-science/data/raw/main/items.json")
df_item.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>85123A</td>
      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>
      <td>2.55</td>
    </tr>
    <tr>
      <th>1</th>
      <td>71053</td>
      <td>WHITE METAL LANTERN</td>
      <td>3.39</td>
    </tr>
    <tr>
      <th>2</th>
      <td>84406B</td>
      <td>CREAM CUPID HEARTS COAT HANGER</td>
      <td>2.75</td>
    </tr>
    <tr>
      <th>3</th>
      <td>84029G</td>
      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>
      <td>3.39</td>
    </tr>
    <tr>
      <th>4</th>
      <td>84029E</td>
      <td>RED WOOLLY HOTTIE WHITE HEART.</td>
      <td>3.39</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_purchase = pd.read_json("https://github.com/umsi-data-science/data/raw/main/purchases.json")
df_purchase.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>StockCodeSC</th>
      <th>Quantity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>SC85123A</td>
      <td>6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536365</td>
      <td>SC71053</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536365</td>
      <td>SC84406B</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536365</td>
      <td>SC84029G</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536365</td>
      <td>SC84029E</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div>



By the above codes, we have loaded invoice, purchase, item data.

### Invoice data


```python
df_invoice.shape
```




    (25943, 4)



Original invoice data has 25943 rows.

**Invoice number**

Since we are only interested in the invoices that are shipped, let's focus on the invoices that do not start with 'c'.


```python
np.sum(df_invoice.InvoiceNo.str.startswith('C'))
```




    3837



There is a total of 3837 rows that are related to the invoices not shipped.


```python
df_invoice_shipped = df_invoice[df_invoice.InvoiceNo.str.startswith('C') == False]
df_invoice_shipped.shape
```




    (22106, 4)



df_invoice_shipped has the invoices data that are shipped. df_invoice_shipped has a total of 22106 rows.


```python
df_invoice_shipped[df_invoice_shipped.InvoiceNo.str.startswith('5') == False]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15466</th>
      <td>A563185</td>
      <td>8/12/11 14:50</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>15467</th>
      <td>A563186</td>
      <td>8/12/11 14:51</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>15468</th>
      <td>A563187</td>
      <td>8/12/11 14:52</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
  </tbody>
</table>
</div>



Three invoice numbers are different from general other invoice numbers in that they start with "A". Let's check if purchase data also has these three invoice numbers.


```python
df_purchase[df_purchase.InvoiceNo.str.startswith('A')]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>StockCodeSC</th>
      <th>Quantity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>299982</th>
      <td>A563185</td>
      <td>SCB</td>
      <td>1</td>
    </tr>
    <tr>
      <th>299983</th>
      <td>A563186</td>
      <td>SCB</td>
      <td>1</td>
    </tr>
    <tr>
      <th>299984</th>
      <td>A563187</td>
      <td>SCB</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



Since purchase data has all the information related to these three abnormal invoice numbers, the analysis proceeds without deleting these three invoice numbers.

**Customer ID**


```python
df_invoice_shipped.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 22106 entries, 0 to 25942
    Data columns (total 4 columns):
     #   Column       Non-Null Count  Dtype  
    ---  ------       --------------  -----  
     0   InvoiceNo    22106 non-null  object 
     1   InvoiceDate  22106 non-null  object 
     2   CustomerID   18566 non-null  float64
     3   Country      22106 non-null  object 
    dtypes: float64(1), object(3)
    memory usage: 863.5+ KB



```python
np.sum(df_invoice_shipped.CustomerID.isnull())
```




    3540



We can check that there are 3540 missing values in the "CumstomerID" column. <span style="color:magenta"> (Q1 - 4)


```python
df_invoice_shipped[df_invoice_shipped.CustomerID.isnull()]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>46</th>
      <td>536414</td>
      <td>12/1/10 11:52</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>89</th>
      <td>536544</td>
      <td>12/1/10 14:32</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>90</th>
      <td>536545</td>
      <td>12/1/10 14:32</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>91</th>
      <td>536546</td>
      <td>12/1/10 14:33</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>92</th>
      <td>536547</td>
      <td>12/1/10 14:33</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>25859</th>
      <td>581435</td>
      <td>12/8/11 16:14</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>25863</th>
      <td>581439</td>
      <td>12/8/11 16:30</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>25911</th>
      <td>581492</td>
      <td>12/9/11 10:03</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>25916</th>
      <td>581497</td>
      <td>12/9/11 10:23</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>25917</th>
      <td>581498</td>
      <td>12/9/11 10:26</td>
      <td>NaN</td>
      <td>United Kingdom</td>
    </tr>
  </tbody>
</table>
<p>3540 rows × 4 columns</p>
</div>



Even though invoice df_invoice_shipped has missing values in the "CustomerID" column, we can get other purchase information for each transaction by invoice numbers. Therefore, the analysis proceeds without deleting rows with a missing value in CustomerID.

**Country**


```python
df_invoice_shipped.Country.value_counts()
```




    United Kingdom    20161
    Germany             457
    France              393
    EIRE                289
    Belgium              98
                      ...  
    Czech Republic        2
    Saudi Arabia          1
    Brazil                1
    Lebanon               1
    RSA                   1
    Name: Country, Length: 38, dtype: int64



The above data shows how many rows exist for each country. We can check there is a total of 13 abnormal "Unspecified" rows in the "Country" column, which can be similar to a missing value.


```python
df_invoice_shipped[df_invoice_shipped.Country == "Unspecified"]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7594</th>
      <td>549687</td>
      <td>4/11/11 13:29</td>
      <td>12363.0</td>
      <td>Unspecified</td>
    </tr>
    <tr>
      <th>9350</th>
      <td>552695</td>
      <td>5/10/11 15:31</td>
      <td>16320.0</td>
      <td>Unspecified</td>
    </tr>
    <tr>
      <th>10041</th>
      <td>553857</td>
      <td>5/19/11 13:30</td>
      <td>NaN</td>
      <td>Unspecified</td>
    </tr>
    <tr>
      <th>12173</th>
      <td>557499</td>
      <td>6/20/11 15:25</td>
      <td>16320.0</td>
      <td>Unspecified</td>
    </tr>
    <tr>
      <th>13339</th>
      <td>559521</td>
      <td>7/8/11 16:26</td>
      <td>NaN</td>
      <td>Unspecified</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>15911</th>
      <td>563947</td>
      <td>8/22/11 10:18</td>
      <td>12363.0</td>
      <td>Unspecified</td>
    </tr>
    <tr>
      <th>15946</th>
      <td>564051</td>
      <td>8/22/11 13:32</td>
      <td>14265.0</td>
      <td>Unspecified</td>
    </tr>
    <tr>
      <th>16621</th>
      <td>565303</td>
      <td>9/2/11 12:17</td>
      <td>NaN</td>
      <td>Unspecified</td>
    </tr>
    <tr>
      <th>23151</th>
      <td>576646</td>
      <td>11/16/11 10:18</td>
      <td>NaN</td>
      <td>Unspecified</td>
    </tr>
    <tr>
      <th>24289</th>
      <td>578539</td>
      <td>11/24/11 14:55</td>
      <td>NaN</td>
      <td>Unspecified</td>
    </tr>
  </tbody>
</table>
<p>13 rows × 4 columns</p>
</div>



However, since we can also get other purchase information for each transaction by invoice numbers, the analysis proceeds without deleting "Unspecified" rows in the "Country" column.

**Invoice date**


```python
np.sum(df_invoice_shipped.InvoiceDate.isnull())
```




    0



There is no missing value in invoice date. <span style="color:magenta"> (Q1 - 4)

In principle, one invoice number should have one invoice date.


```python
df_invoice_shipped = df_invoice_shipped.merge(df_invoice_shipped.groupby("InvoiceNo").count().InvoiceDate.reset_index().rename({"InvoiceDate" : "InvoiceDateCount"}, axis = 1), on = "InvoiceNo", how = "left")
df_invoice_shipped.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
      <th>InvoiceDateCount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>12/1/10 8:26</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536366</td>
      <td>12/1/10 8:28</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536367</td>
      <td>12/1/10 8:34</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536368</td>
      <td>12/1/10 8:34</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536369</td>
      <td>12/1/10 8:35</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_invoice_shipped.InvoiceDateCount.sort_values()
```




    0        1
    14736    1
    14735    1
    14734    1
    14733    1
            ..
    6708     2
    6863     2
    6862     2
    12573    2
    5328     2
    Name: InvoiceDateCount, Length: 22106, dtype: int64



From the above data, we can see that several invoice numbers have two different invoice dates.


```python
pd.set_option('display.max_rows', df_invoice_shipped.shape[0]+1)
```


```python
df_invoice_shipped.loc[df_invoice_shipped[df_invoice_shipped.InvoiceDateCount > 1].sort_values(by = ["InvoiceNo", "InvoiceDate", "CustomerID"]).index]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
      <th>InvoiceDateCount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>130</th>
      <td>536591</td>
      <td>12/1/10 16:57</td>
      <td>14606.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>131</th>
      <td>536591</td>
      <td>12/1/10 16:58</td>
      <td>14606.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1789</th>
      <td>540185</td>
      <td>1/5/11 13:40</td>
      <td>14653.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1790</th>
      <td>540185</td>
      <td>1/5/11 13:41</td>
      <td>14653.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2374</th>
      <td>541596</td>
      <td>1/19/11 16:18</td>
      <td>17602.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2375</th>
      <td>541596</td>
      <td>1/19/11 16:19</td>
      <td>17602.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2389</th>
      <td>541631</td>
      <td>1/20/11 10:47</td>
      <td>12637.0</td>
      <td>France</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2390</th>
      <td>541631</td>
      <td>1/20/11 10:48</td>
      <td>12637.0</td>
      <td>France</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2454</th>
      <td>541809</td>
      <td>1/21/11 14:58</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2455</th>
      <td>541809</td>
      <td>1/21/11 14:59</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2462</th>
      <td>541816</td>
      <td>1/21/11 15:56</td>
      <td>17799.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2463</th>
      <td>541816</td>
      <td>1/21/11 15:57</td>
      <td>17799.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2481</th>
      <td>541849</td>
      <td>1/23/11 13:33</td>
      <td>13230.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2482</th>
      <td>541849</td>
      <td>1/23/11 13:34</td>
      <td>13230.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2640</th>
      <td>542217</td>
      <td>1/26/11 12:35</td>
      <td>14606.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2641</th>
      <td>542217</td>
      <td>1/26/11 12:36</td>
      <td>14606.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2942</th>
      <td>542806</td>
      <td>2/1/11 11:19</td>
      <td>12836.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2943</th>
      <td>542806</td>
      <td>2/1/11 11:20</td>
      <td>12836.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3116</th>
      <td>543171</td>
      <td>2/4/11 9:10</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3117</th>
      <td>543171</td>
      <td>2/4/11 9:11</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3124</th>
      <td>543179</td>
      <td>2/4/11 10:31</td>
      <td>12754.0</td>
      <td>Japan</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3125</th>
      <td>543179</td>
      <td>2/4/11 10:32</td>
      <td>12754.0</td>
      <td>Japan</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3128</th>
      <td>543182</td>
      <td>2/4/11 10:39</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3129</th>
      <td>543182</td>
      <td>2/4/11 10:40</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3408</th>
      <td>543777</td>
      <td>2/11/11 16:19</td>
      <td>15406.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3409</th>
      <td>543777</td>
      <td>2/11/11 16:20</td>
      <td>15406.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3597</th>
      <td>544186</td>
      <td>2/16/11 15:55</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3598</th>
      <td>544186</td>
      <td>2/16/11 15:56</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3825</th>
      <td>544667</td>
      <td>2/22/11 15:09</td>
      <td>17511.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3826</th>
      <td>544667</td>
      <td>2/22/11 15:10</td>
      <td>17511.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3956</th>
      <td>544926</td>
      <td>2/24/11 17:50</td>
      <td>13468.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3957</th>
      <td>544926</td>
      <td>2/24/11 17:51</td>
      <td>13468.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4212</th>
      <td>545460</td>
      <td>3/2/11 17:32</td>
      <td>13230.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4213</th>
      <td>545460</td>
      <td>3/2/11 17:33</td>
      <td>13230.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4369</th>
      <td>545713</td>
      <td>3/7/11 10:11</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4370</th>
      <td>545713</td>
      <td>3/7/11 10:12</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4660</th>
      <td>546388</td>
      <td>3/11/11 13:42</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4661</th>
      <td>546388</td>
      <td>3/11/11 13:43</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4957</th>
      <td>546986</td>
      <td>3/18/11 12:55</td>
      <td>14194.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4958</th>
      <td>546986</td>
      <td>3/18/11 12:56</td>
      <td>14194.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5328</th>
      <td>547690</td>
      <td>3/24/11 14:55</td>
      <td>16063.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5329</th>
      <td>547690</td>
      <td>3/24/11 14:56</td>
      <td>16063.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5591</th>
      <td>548203</td>
      <td>3/29/11 16:40</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5592</th>
      <td>548203</td>
      <td>3/29/11 16:41</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6148</th>
      <td>549245</td>
      <td>4/7/11 11:59</td>
      <td>15005.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6149</th>
      <td>549245</td>
      <td>4/7/11 12:00</td>
      <td>15005.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6308</th>
      <td>549524</td>
      <td>4/8/11 15:41</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6309</th>
      <td>549524</td>
      <td>4/8/11 15:42</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6708</th>
      <td>550320</td>
      <td>4/17/11 12:37</td>
      <td>12748.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6709</th>
      <td>550320</td>
      <td>4/17/11 12:38</td>
      <td>12748.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6722</th>
      <td>550333</td>
      <td>4/17/11 14:05</td>
      <td>15410.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6723</th>
      <td>550333</td>
      <td>4/17/11 14:06</td>
      <td>15410.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6858</th>
      <td>550641</td>
      <td>4/19/11 15:53</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6859</th>
      <td>550641</td>
      <td>4/19/11 15:54</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6862</th>
      <td>550645</td>
      <td>4/19/11 16:30</td>
      <td>16098.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6863</th>
      <td>550645</td>
      <td>4/19/11 16:31</td>
      <td>16098.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>7550</th>
      <td>552000</td>
      <td>5/5/11 15:55</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>7551</th>
      <td>552000</td>
      <td>5/5/11 15:56</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>8183</th>
      <td>553199</td>
      <td>5/15/11 15:13</td>
      <td>17758.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>8184</th>
      <td>553199</td>
      <td>5/15/11 15:14</td>
      <td>17758.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>8242</th>
      <td>553375</td>
      <td>5/16/11 14:52</td>
      <td>14911.0</td>
      <td>EIRE</td>
      <td>2</td>
    </tr>
    <tr>
      <th>8243</th>
      <td>553375</td>
      <td>5/16/11 14:53</td>
      <td>14911.0</td>
      <td>EIRE</td>
      <td>2</td>
    </tr>
    <tr>
      <th>8352</th>
      <td>553556</td>
      <td>5/17/11 16:48</td>
      <td>17530.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>8353</th>
      <td>553556</td>
      <td>5/17/11 16:49</td>
      <td>17530.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>8671</th>
      <td>554116</td>
      <td>5/22/11 15:11</td>
      <td>14514.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>8672</th>
      <td>554116</td>
      <td>5/22/11 15:12</td>
      <td>14514.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>10560</th>
      <td>558086</td>
      <td>6/26/11 11:58</td>
      <td>16728.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>10561</th>
      <td>558086</td>
      <td>6/26/11 11:59</td>
      <td>16728.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>12182</th>
      <td>561369</td>
      <td>7/26/11 16:21</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>12183</th>
      <td>561369</td>
      <td>7/26/11 16:22</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>12572</th>
      <td>562128</td>
      <td>8/3/11 9:06</td>
      <td>16150.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>12573</th>
      <td>562128</td>
      <td>8/3/11 9:07</td>
      <td>16150.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>13124</th>
      <td>563245</td>
      <td>8/15/11 10:53</td>
      <td>16272.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>13125</th>
      <td>563245</td>
      <td>8/15/11 10:54</td>
      <td>16272.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>14981</th>
      <td>567183</td>
      <td>9/18/11 15:32</td>
      <td>14769.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>14982</th>
      <td>567183</td>
      <td>9/18/11 15:33</td>
      <td>14769.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>17238</th>
      <td>571735</td>
      <td>10/19/11 10:03</td>
      <td>14229.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>17239</th>
      <td>571735</td>
      <td>10/19/11 10:04</td>
      <td>14229.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>18394</th>
      <td>574076</td>
      <td>11/2/11 15:37</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>18395</th>
      <td>574076</td>
      <td>11/2/11 15:38</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>19373</th>
      <td>576057</td>
      <td>11/13/11 15:05</td>
      <td>15861.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>19374</th>
      <td>576057</td>
      <td>11/13/11 15:06</td>
      <td>15861.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>20668</th>
      <td>578548</td>
      <td>11/24/11 15:02</td>
      <td>17345.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
    <tr>
      <th>20669</th>
      <td>578548</td>
      <td>11/24/11 15:03</td>
      <td>17345.0</td>
      <td>United Kingdom</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>



The invoice dates in each invoice number differed by only one minute each other, and other columns are all same. So I will only use the earlier of the two dates.


```python
pd.set_option('display.max_rows', 10)
```


```python
df_invoice_shipped
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
      <th>InvoiceDateCount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>12/1/10 8:26</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536366</td>
      <td>12/1/10 8:28</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536367</td>
      <td>12/1/10 8:34</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536368</td>
      <td>12/1/10 8:34</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536369</td>
      <td>12/1/10 8:35</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>22101</th>
      <td>581583</td>
      <td>12/9/11 12:23</td>
      <td>13777.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>22102</th>
      <td>581584</td>
      <td>12/9/11 12:25</td>
      <td>13777.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>22103</th>
      <td>581585</td>
      <td>12/9/11 12:31</td>
      <td>15804.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>22104</th>
      <td>581586</td>
      <td>12/9/11 12:49</td>
      <td>13113.0</td>
      <td>United Kingdom</td>
      <td>1</td>
    </tr>
    <tr>
      <th>22105</th>
      <td>581587</td>
      <td>12/9/11 12:50</td>
      <td>12680.0</td>
      <td>France</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>22106 rows × 5 columns</p>
</div>




```python
df_invoice_shipped["partition_row_number"] = df_invoice_shipped.sort_values(by = ["InvoiceNo", "InvoiceDate"]).groupby("InvoiceNo").cumcount() + 1
```


```python
df_invoice_shipped.loc[df_invoice_shipped[df_invoice_shipped.InvoiceDateCount > 1].sort_values(by = ["InvoiceNo", "InvoiceDate", "CustomerID"]).index]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
      <th>InvoiceDateCount</th>
      <th>partition_row_number</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>130</th>
      <td>536591</td>
      <td>12/1/10 16:57</td>
      <td>14606.0</td>
      <td>United Kingdom</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>131</th>
      <td>536591</td>
      <td>12/1/10 16:58</td>
      <td>14606.0</td>
      <td>United Kingdom</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1789</th>
      <td>540185</td>
      <td>1/5/11 13:40</td>
      <td>14653.0</td>
      <td>United Kingdom</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1790</th>
      <td>540185</td>
      <td>1/5/11 13:41</td>
      <td>14653.0</td>
      <td>United Kingdom</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2374</th>
      <td>541596</td>
      <td>1/19/11 16:18</td>
      <td>17602.0</td>
      <td>United Kingdom</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>18395</th>
      <td>574076</td>
      <td>11/2/11 15:38</td>
      <td>NaN</td>
      <td>United Kingdom</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>19373</th>
      <td>576057</td>
      <td>11/13/11 15:05</td>
      <td>15861.0</td>
      <td>United Kingdom</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>19374</th>
      <td>576057</td>
      <td>11/13/11 15:06</td>
      <td>15861.0</td>
      <td>United Kingdom</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>20668</th>
      <td>578548</td>
      <td>11/24/11 15:02</td>
      <td>17345.0</td>
      <td>United Kingdom</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>20669</th>
      <td>578548</td>
      <td>11/24/11 15:03</td>
      <td>17345.0</td>
      <td>United Kingdom</td>
      <td>2</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>84 rows × 6 columns</p>
</div>




```python
df_invoice_shipped = df_invoice_shipped[df_invoice_shipped.partition_row_number == 1]
df_invoice_shipped.drop(["InvoiceDateCount", "partition_row_number"], axis = 1, inplace = True)
df_invoice_shipped.head()
```

    /opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      return super().drop(





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>12/1/10 8:26</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536366</td>
      <td>12/1/10 8:28</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536367</td>
      <td>12/1/10 8:34</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536368</td>
      <td>12/1/10 8:34</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536369</td>
      <td>12/1/10 8:35</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_invoice_shipped.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 22064 entries, 0 to 22105
    Data columns (total 4 columns):
     #   Column       Non-Null Count  Dtype  
    ---  ------       --------------  -----  
     0   InvoiceNo    22064 non-null  object 
     1   InvoiceDate  22064 non-null  object 
     2   CustomerID   18536 non-null  float64
     3   Country      22064 non-null  object 
    dtypes: float64(1), object(3)
    memory usage: 861.9+ KB


The column "InvoiceDate" is now object type, so I need to change this column to the DateTime type.


```python
df_invoice_shipped["InvoiceDate"] = pd.to_datetime(df_invoice_shipped["InvoiceDate"])
df_invoice_shipped.head()
```

    /var/folders/kb/9bgdwxjn0b751yc9w59v1ll00000gn/T/ipykernel_53930/964488366.py:1: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      df_invoice_shipped["InvoiceDate"] = pd.to_datetime(df_invoice_shipped["InvoiceDate"])





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536366</td>
      <td>2010-12-01 08:28:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536367</td>
      <td>2010-12-01 08:34:00</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536368</td>
      <td>2010-12-01 08:34:00</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536369</td>
      <td>2010-12-01 08:35:00</td>
      <td>13047.0</td>
      <td>United Kingdom</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_invoice_shipped.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 22064 entries, 0 to 22105
    Data columns (total 4 columns):
     #   Column       Non-Null Count  Dtype         
    ---  ------       --------------  -----         
     0   InvoiceNo    22064 non-null  object        
     1   InvoiceDate  22064 non-null  datetime64[ns]
     2   CustomerID   18536 non-null  float64       
     3   Country      22064 non-null  object        
    dtypes: datetime64[ns](1), float64(1), object(2)
    memory usage: 861.9+ KB


**invoice data after preprocessing**


```python
df_invoice_shipped.shape
```




    (22064, 4)



After completing all the preprocessing for the invoice data, the invoice data has a total of 22064 rows and 4 columns. 


```python
len(df_invoice_shipped.InvoiceNo.unique())
```




    22064



22064 unique invoices have been placed. <span style="color:magenta"> (Q1-2)


```python
len(df_invoice_shipped.CustomerID.unique())
```




    4340



There is a total of 4339 unique customers excluding missing values. <span style="color:magenta"> (Q1-3)

### Item data


```python
df_item.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>85123A</td>
      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>
      <td>2.55</td>
    </tr>
    <tr>
      <th>1</th>
      <td>71053</td>
      <td>WHITE METAL LANTERN</td>
      <td>3.39</td>
    </tr>
    <tr>
      <th>2</th>
      <td>84406B</td>
      <td>CREAM CUPID HEARTS COAT HANGER</td>
      <td>2.75</td>
    </tr>
    <tr>
      <th>3</th>
      <td>84029G</td>
      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>
      <td>3.39</td>
    </tr>
    <tr>
      <th>4</th>
      <td>84029E</td>
      <td>RED WOOLLY HOTTIE WHITE HEART.</td>
      <td>3.39</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_item.shape
```




    (4070, 3)



Original item data has 4070 rows and 3 columns

**stock code**


```python
df_item.loc[df_item.StockCode.sort_values().index]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>31</th>
      <td>10002</td>
      <td>INFLATABLE POLITICAL GLOBE</td>
      <td>0.85</td>
    </tr>
    <tr>
      <th>3147</th>
      <td>10080</td>
      <td>GROOVY CACTUS INFLATABLE</td>
      <td>0.85</td>
    </tr>
    <tr>
      <th>1636</th>
      <td>10120</td>
      <td>DOGGY RUBBER</td>
      <td>0.21</td>
    </tr>
    <tr>
      <th>1635</th>
      <td>10123C</td>
      <td>HEARTS WRAPPING TAPE</td>
      <td>0.65</td>
    </tr>
    <tr>
      <th>3308</th>
      <td>10123G</td>
      <td>None</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2843</th>
      <td>gift_0001_20</td>
      <td>Dotcomgiftshop Gift Voucher £20.00</td>
      <td>17.02</td>
    </tr>
    <tr>
      <th>2842</th>
      <td>gift_0001_30</td>
      <td>Dotcomgiftshop Gift Voucher £30.00</td>
      <td>25.53</td>
    </tr>
    <tr>
      <th>2774</th>
      <td>gift_0001_40</td>
      <td>Dotcomgiftshop Gift Voucher £40.00</td>
      <td>34.04</td>
    </tr>
    <tr>
      <th>2815</th>
      <td>gift_0001_50</td>
      <td>Dotcomgiftshop Gift Voucher £50.00</td>
      <td>42.55</td>
    </tr>
    <tr>
      <th>2791</th>
      <td>m</td>
      <td>Manual</td>
      <td>2.55</td>
    </tr>
  </tbody>
</table>
<p>4070 rows × 3 columns</p>
</div>



In the above data, the stock code in the last row is abnormal "m". However, since this stock code has a valid description and unit price, it can be considered as the valid stock code.


```python
np.sum(df_item.StockCode.isnull())
```




    0



There is no missing value in the stock code column. <span style="color:magenta"> (Q1 - 4)

I think in principle there should be one description and price for each stock code.


```python
df_item = df_item.merge(df_item.groupby("StockCode").count().reset_index().rename({"Description" : "description_count", "UnitPrice" : "unit_price_count"}, axis = 1), on = "StockCode", how = "left")
df_item
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
      <th>description_count</th>
      <th>unit_price_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>85123A</td>
      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>
      <td>2.55</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>71053</td>
      <td>WHITE METAL LANTERN</td>
      <td>3.39</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>84406B</td>
      <td>CREAM CUPID HEARTS COAT HANGER</td>
      <td>2.75</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>84029G</td>
      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>
      <td>3.39</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>84029E</td>
      <td>RED WOOLLY HOTTIE WHITE HEART.</td>
      <td>3.39</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4065</th>
      <td>85179a</td>
      <td>GREEN BITTY LIGHT CHAIN</td>
      <td>2.46</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4066</th>
      <td>23617</td>
      <td>SET 10 CARDS SWIRLY XMAS TREE 17104</td>
      <td>2.91</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4067</th>
      <td>90214U</td>
      <td>LETTER "U" BLING KEY RING</td>
      <td>0.29</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4068</th>
      <td>47591b</td>
      <td>SCOTTIES CHILDRENS APRON</td>
      <td>4.13</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4069</th>
      <td>23843</td>
      <td>PAPER CRAFT , LITTLE BIRDIE</td>
      <td>2.08</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>4070 rows × 5 columns</p>
</div>




```python
df_item.description_count.sort_values()
```




    3303    0
    2913    0
    2399    0
    2400    0
    2401    0
           ..
    1363    1
    1364    1
    1365    1
    1352    1
    4069    1
    Name: description_count, Length: 4070, dtype: int64




```python
df_item.unit_price_count.sort_values()
```




    0       1
    2705    1
    2706    1
    2707    1
    2708    1
           ..
    1362    1
    1363    1
    1364    1
    1351    1
    4069    1
    Name: unit_price_count, Length: 4070, dtype: int64



By above two results, we can see that each stock code has at most one description and price value as I initially thought. So the stock code has nothing to deal with.


```python
df_item.drop(["description_count", "unit_price_count"], axis = 1, inplace = True)
```


```python
len(df_item.StockCode.unique())
```




    4070



There is a total of 4070 unique items. <span style="color:magenta"> (Q1 - 5)

**Unit price**


```python
df_item.loc[df_item.UnitPrice.sort_values().index]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3260</th>
      <td>21614</td>
      <td>None</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>3283</th>
      <td>21274</td>
      <td>None</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>3282</th>
      <td>84845D</td>
      <td>None</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>3280</th>
      <td>84876C</td>
      <td>None</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>3279</th>
      <td>84875A</td>
      <td>None</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>190</th>
      <td>22827</td>
      <td>RUSTIC  SEVENTEEN DRAWER SIDEBOARD</td>
      <td>165.00</td>
    </tr>
    <tr>
      <th>2541</th>
      <td>22826</td>
      <td>LOVE SEAT ANTIQUE WHITE METAL</td>
      <td>175.00</td>
    </tr>
    <tr>
      <th>1591</th>
      <td>22655</td>
      <td>VINTAGE RED KITCHEN CABINET</td>
      <td>295.00</td>
    </tr>
    <tr>
      <th>952</th>
      <td>DOT</td>
      <td>DOTCOM POSTAGE</td>
      <td>569.77</td>
    </tr>
    <tr>
      <th>3753</th>
      <td>B</td>
      <td>Adjust bad debt</td>
      <td>11062.06</td>
    </tr>
  </tbody>
</table>
<p>4070 rows × 3 columns</p>
</div>




```python
df_item[df_item.UnitPrice == 0].shape
```




    (215, 3)



We can see that the minimum value of the unit price is 0 and the maximum value of the unit price is 11062.06. There is a total of 215 stock codes that have 0 unit prices.


```python
df_item[df_item.UnitPrice == 0].Description.unique()
```




    array([None, '?', 'check', 'FRENCH BLUE METAL DOOR SIGN 4',
           'CHILDS GARDEN TROWEL BLUE ', 'CHILDS GARDEN RAKE BLUE',
           'LUNCH BOX WITH CUTLERY FAIRY CAKES ',
           'TEATIME FUNKY FLOWER BACKPACK FOR 2', 'damages', 'Given away',
           'thrown away', 'throw away', "thrown away-can't sell.",
           "thrown away-can't sell", 'mailout ', 'mailout',
           'Thrown away-rusty', 'wet damaged', 'Damaged',
           'TRAVEL CARD WALLET DOTCOMGIFTSHOP', 'ebay', 'found', 'adjustment',
           'Found by jackie', 'Unsaleable, destroyed.'], dtype=object)



The list above is a collection of unique descriptions of stock code with a zero unit price. There are cases where the description is none, but I think it is difficult to interpret the case where the unit price is 0 as a missing value. So the unit price has nothing to deal with.

**Description**


```python
df_item[df_item.Description.isnull()]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1041</th>
      <td>21134</td>
      <td>None</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1042</th>
      <td>22145</td>
      <td>None</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1043</th>
      <td>37509</td>
      <td>None</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1047</th>
      <td>85226A</td>
      <td>None</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1048</th>
      <td>85044</td>
      <td>None</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>3723</th>
      <td>37477C</td>
      <td>None</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3839</th>
      <td>35592T</td>
      <td>None</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3860</th>
      <td>35598A</td>
      <td>None</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3958</th>
      <td>23702</td>
      <td>None</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4050</th>
      <td>84971L</td>
      <td>None</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>176 rows × 3 columns</p>
</div>



There are 176 missing values in the description column. <span style="color:magenta"> (Q1 - 5)

### Purchase data


```python
df_purchase.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>StockCodeSC</th>
      <th>Quantity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>SC85123A</td>
      <td>6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536365</td>
      <td>SC71053</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536365</td>
      <td>SC84406B</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536365</td>
      <td>SC84029G</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536365</td>
      <td>SC84029E</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_purchase.shape
```




    (541909, 3)



Original purchase data has 541909 rows and 3 columns.

**Invoice number**


```python
np.sum(df_purchase.InvoiceNo.isnull())
```




    0



There is no missing value in the invoice number.  <span style="color:magenta"> (Q1 - 5)

Since we are not interested in the invoice numbers that were canceled, let's delete these rows.


```python
df_purchase_shipped = df_purchase[df_purchase.InvoiceNo.str.startswith("C") == False]
df_purchase_shipped.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>StockCodeSC</th>
      <th>Quantity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>SC85123A</td>
      <td>6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536365</td>
      <td>SC71053</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536365</td>
      <td>SC84406B</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536365</td>
      <td>SC84029G</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536365</td>
      <td>SC84029E</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div>



**Stock code**


```python
np.sum(df_purchase_shipped.StockCodeSC.isnull())
```




    0



There is no missing value in the stock code. <span style="color:magenta"> (Q1 - 5)

In the previous item data, stock code was used as the column name "StockCode". However, since "StockCodeSC" is used in the purchase data, let's unify it as "Stockcode".


```python
np.sum(df_purchase_shipped.StockCodeSC.str.startswith("SC") == False)
```




    0



All "StockcodeSC" values start with "SC", so I have to delete "SC" in front.


```python
df_purchase_shipped["StockCode"] = df_purchase_shipped.StockCodeSC.str.split("SC").str[1]
```

    /var/folders/kb/9bgdwxjn0b751yc9w59v1ll00000gn/T/ipykernel_53930/3471317207.py:1: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      df_purchase_shipped["StockCode"] = df_purchase_shipped.StockCodeSC.str.split("SC").str[1]



```python
df_purchase_shipped.drop("StockCodeSC", inplace = True, axis = 1)
```

    /opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      return super().drop(



```python
df_purchase_shipped.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>Quantity</th>
      <th>StockCode</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>6</td>
      <td>85123A</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536365</td>
      <td>6</td>
      <td>71053</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536365</td>
      <td>8</td>
      <td>84406B</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536365</td>
      <td>6</td>
      <td>84029G</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536365</td>
      <td>6</td>
      <td>84029E</td>
    </tr>
  </tbody>
</table>
</div>



**Quantity**


```python
np.sum(df_purchase_shipped.Quantity.isnull())
```




    0



There is no missing value in the quantity column. <span style="color:magenta"> (Q1 - 5)


```python
df_purchase_shipped.Quantity.sort_values()
```




    225530    -9600
    225529    -9600
    225528    -9058
    115818    -5368
    431381    -4830
              ...  
    421632     4800
    74614      5568
    502122    12540
    61619     74215
    540421    80995
    Name: Quantity, Length: 532621, dtype: int64



There are some minus values in the quantity column. Let's check these values.


```python
df_purchase_shipped[df_purchase_shipped.Quantity <= 0]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>Quantity</th>
      <th>StockCode</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2406</th>
      <td>536589</td>
      <td>-10</td>
      <td>21777</td>
    </tr>
    <tr>
      <th>4347</th>
      <td>536764</td>
      <td>-38</td>
      <td>84952C</td>
    </tr>
    <tr>
      <th>7188</th>
      <td>536996</td>
      <td>-20</td>
      <td>22712</td>
    </tr>
    <tr>
      <th>7189</th>
      <td>536997</td>
      <td>-20</td>
      <td>22028</td>
    </tr>
    <tr>
      <th>7190</th>
      <td>536998</td>
      <td>-6</td>
      <td>85067</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>535333</th>
      <td>581210</td>
      <td>-26</td>
      <td>23395</td>
    </tr>
    <tr>
      <th>535335</th>
      <td>581212</td>
      <td>-1050</td>
      <td>22578</td>
    </tr>
    <tr>
      <th>535336</th>
      <td>581213</td>
      <td>-30</td>
      <td>22576</td>
    </tr>
    <tr>
      <th>536908</th>
      <td>581226</td>
      <td>-338</td>
      <td>23090</td>
    </tr>
    <tr>
      <th>538919</th>
      <td>581422</td>
      <td>-235</td>
      <td>23169</td>
    </tr>
  </tbody>
</table>
<p>1336 rows × 3 columns</p>
</div>



For now, I don't know for sure what the negative quantity means, so I'm going to leave it without deleting it for now. Later, when I need to use the quantity column, I will handle these negative values appropriately.

### Merge

First, I extracted only shipped records from the invoice data and will merge the other two tables based on this invoice data. When the purchase data is combined based on the invoice number of the invoice data, the information about which items and how many were traded in each transaction is combined. By combining the item data based on the stock code of the combined data, I can get the description and unit price information of each item traded. Because data can be combined only with the invoice number and stock code, first create data that has all information even if there are missing values in other columns. When performing subsequent analysis, the missing values will be appropriately handled according to the situation. 
<span style="color:magenta"> (Q1 - 6)


```python
df_merged = df_invoice_shipped.merge(df_purchase_shipped, on = "InvoiceNo", how = "left").merge(df_item, on = "StockCode", how = "left")
df_merged
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
      <th>Quantity</th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>6</td>
      <td>85123A</td>
      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>
      <td>2.55</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>6</td>
      <td>71053</td>
      <td>WHITE METAL LANTERN</td>
      <td>3.39</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>8</td>
      <td>84406B</td>
      <td>CREAM CUPID HEARTS COAT HANGER</td>
      <td>2.75</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>6</td>
      <td>84029G</td>
      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>
      <td>3.39</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>6</td>
      <td>84029E</td>
      <td>RED WOOLLY HOTTIE WHITE HEART.</td>
      <td>3.39</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>532616</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>12</td>
      <td>22613</td>
      <td>PACK OF 20 SPACEBOY NAPKINS</td>
      <td>1.66</td>
    </tr>
    <tr>
      <th>532617</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>6</td>
      <td>22899</td>
      <td>CHILDREN'S APRON DOLLY GIRL</td>
      <td>2.10</td>
    </tr>
    <tr>
      <th>532618</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>4</td>
      <td>23254</td>
      <td>CHILDRENS CUTLERY DOLLY GIRL</td>
      <td>4.15</td>
    </tr>
    <tr>
      <th>532619</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>4</td>
      <td>23255</td>
      <td>CHILDRENS CUTLERY CIRCUS PARADE</td>
      <td>4.15</td>
    </tr>
    <tr>
      <th>532620</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>3</td>
      <td>22138</td>
      <td>BAKING SET 9 PIECE RETROSPOT</td>
      <td>4.95</td>
    </tr>
  </tbody>
</table>
<p>532621 rows × 8 columns</p>
</div>




```python
df_merged.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 532621 entries, 0 to 532620
    Data columns (total 8 columns):
     #   Column       Non-Null Count   Dtype         
    ---  ------       --------------   -----         
     0   InvoiceNo    532621 non-null  object        
     1   InvoiceDate  532621 non-null  datetime64[ns]
     2   CustomerID   397924 non-null  float64       
     3   Country      532621 non-null  object        
     4   Quantity     532621 non-null  int64         
     5   StockCode    532621 non-null  object        
     6   Description  531204 non-null  object        
     7   UnitPrice    532621 non-null  float64       
    dtypes: datetime64[ns](1), float64(2), int64(1), object(4)
    memory usage: 36.6+ MB


Since customer ID means a separate entity rather than a mathematical number, the object type is more appropriate than float. So I will change the customer id to object type.


```python
df_merged = df_merged.astype({"CustomerID" : object})
df_merged.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 532621 entries, 0 to 532620
    Data columns (total 8 columns):
     #   Column       Non-Null Count   Dtype         
    ---  ------       --------------   -----         
     0   InvoiceNo    532621 non-null  object        
     1   InvoiceDate  532621 non-null  datetime64[ns]
     2   CustomerID   397924 non-null  object        
     3   Country      532621 non-null  object        
     4   Quantity     532621 non-null  int64         
     5   StockCode    532621 non-null  object        
     6   Description  531204 non-null  object        
     7   UnitPrice    532621 non-null  float64       
    dtypes: datetime64[ns](1), float64(1), int64(1), object(5)
    memory usage: 36.6+ MB



```python
df_merged = df_merged[["InvoiceNo", "InvoiceDate", "CustomerID", "Country", "StockCode", "Description", "UnitPrice", "Quantity"]]
df_merged
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
      <th>Quantity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>85123A</td>
      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>
      <td>2.55</td>
      <td>6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>71053</td>
      <td>WHITE METAL LANTERN</td>
      <td>3.39</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84406B</td>
      <td>CREAM CUPID HEARTS COAT HANGER</td>
      <td>2.75</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84029G</td>
      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>
      <td>3.39</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84029E</td>
      <td>RED WOOLLY HOTTIE WHITE HEART.</td>
      <td>3.39</td>
      <td>6</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>532616</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>22613</td>
      <td>PACK OF 20 SPACEBOY NAPKINS</td>
      <td>1.66</td>
      <td>12</td>
    </tr>
    <tr>
      <th>532617</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>22899</td>
      <td>CHILDREN'S APRON DOLLY GIRL</td>
      <td>2.10</td>
      <td>6</td>
    </tr>
    <tr>
      <th>532618</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>23254</td>
      <td>CHILDRENS CUTLERY DOLLY GIRL</td>
      <td>4.15</td>
      <td>4</td>
    </tr>
    <tr>
      <th>532619</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>23255</td>
      <td>CHILDRENS CUTLERY CIRCUS PARADE</td>
      <td>4.15</td>
      <td>4</td>
    </tr>
    <tr>
      <th>532620</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>22138</td>
      <td>BAKING SET 9 PIECE RETROSPOT</td>
      <td>4.95</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>532621 rows × 8 columns</p>
</div>



## <span style="color:magenta"> Q2. [10 points] Invoice Analysis </span>
1. For each customer calculate how many total invoices they have placed. List the top 10 customers who have placed an invoice in descending order.
2. Perform a similar calculation but instead of the number of invoices, calculate the total quantity of items ordered for each customer. List the top 10 customers in descending order.
3. Compare the top 10 customers, does it appear that the more invoices a customer have, the greater the total quantity of items? Explain your reasoning.

_Hint: For 2.2, you may need to join two datasets together to answer the question._

###  (Q2 - 1)


```python
pd.DataFrame(df_merged.groupby("CustomerID").InvoiceNo.nunique().sort_values(ascending = False).head(10).reset_index().rename({"InvoiceNo" : "total_invoice_number"}, axis = 1)) \
    .merge(df_merged.groupby("CustomerID").InvoiceDate.min().reset_index().rename({"InvoiceDate" : "min_invoice_date"}, axis = 1), on = "CustomerID", how = "left") \
    .merge(df_merged.groupby("CustomerID").InvoiceDate.max().reset_index().rename({"InvoiceDate" : "max_invoice_date"}, axis = 1), on = "CustomerID", how = "left")
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CustomerID</th>
      <th>total_invoice_number</th>
      <th>min_invoice_date</th>
      <th>max_invoice_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12748.0</td>
      <td>210</td>
      <td>2010-12-01 12:48:00</td>
      <td>2011-12-09 12:20:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>14911.0</td>
      <td>201</td>
      <td>2010-12-01 14:05:00</td>
      <td>2011-12-08 15:54:00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17841.0</td>
      <td>124</td>
      <td>2010-12-01 14:41:00</td>
      <td>2011-12-08 12:07:00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13089.0</td>
      <td>97</td>
      <td>2010-12-05 10:27:00</td>
      <td>2011-12-07 09:02:00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>14606.0</td>
      <td>93</td>
      <td>2010-12-01 16:57:00</td>
      <td>2011-12-08 19:28:00</td>
    </tr>
    <tr>
      <th>5</th>
      <td>15311.0</td>
      <td>91</td>
      <td>2010-12-01 09:41:00</td>
      <td>2011-12-09 12:00:00</td>
    </tr>
    <tr>
      <th>6</th>
      <td>12971.0</td>
      <td>86</td>
      <td>2010-12-02 16:42:00</td>
      <td>2011-12-06 12:20:00</td>
    </tr>
    <tr>
      <th>7</th>
      <td>14646.0</td>
      <td>74</td>
      <td>2010-12-20 10:09:00</td>
      <td>2011-12-08 12:12:00</td>
    </tr>
    <tr>
      <th>8</th>
      <td>16029.0</td>
      <td>63</td>
      <td>2010-12-01 09:57:00</td>
      <td>2011-11-01 10:27:00</td>
    </tr>
    <tr>
      <th>9</th>
      <td>13408.0</td>
      <td>62</td>
      <td>2010-12-01 10:39:00</td>
      <td>2011-12-08 09:05:00</td>
    </tr>
  </tbody>
</table>
</div>



The above customers are the top 10 customers who have placed the invoice in descending order. The largest number of invoices is 210, which is more than three times the number of 62 invoices in the 10th place. All of the top 10 users have placed orders for the same period of about 1 year. 

### (Q2 - 2)


```python
pd.DataFrame(df_merged.groupby("CustomerID").Quantity.sum().sort_values(ascending = False).reset_index().rename({"Quantity" : "total_quantity"}, axis = 1)).head(10) \
    .merge(df_merged.groupby("CustomerID").InvoiceDate.min().reset_index().rename({"InvoiceDate" : "min_invoice_date"}, axis = 1), on = "CustomerID", how = "left") \
    .merge(df_merged.groupby("CustomerID").InvoiceDate.max().reset_index().rename({"InvoiceDate" : "max_invoice_date"}, axis = 1), on = "CustomerID", how = "left")
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CustomerID</th>
      <th>total_quantity</th>
      <th>min_invoice_date</th>
      <th>max_invoice_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>14646.0</td>
      <td>197491</td>
      <td>2010-12-20 10:09:00</td>
      <td>2011-12-08 12:12:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>16446.0</td>
      <td>80997</td>
      <td>2011-05-18 09:52:00</td>
      <td>2011-12-09 09:15:00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14911.0</td>
      <td>80515</td>
      <td>2010-12-01 14:05:00</td>
      <td>2011-12-08 15:54:00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>12415.0</td>
      <td>77670</td>
      <td>2011-01-06 11:12:00</td>
      <td>2011-11-15 14:22:00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>12346.0</td>
      <td>74215</td>
      <td>2011-01-18 10:01:00</td>
      <td>2011-01-18 10:01:00</td>
    </tr>
    <tr>
      <th>5</th>
      <td>17450.0</td>
      <td>69993</td>
      <td>2010-12-07 09:23:00</td>
      <td>2011-12-01 13:29:00</td>
    </tr>
    <tr>
      <th>6</th>
      <td>17511.0</td>
      <td>64549</td>
      <td>2010-12-01 10:19:00</td>
      <td>2011-12-07 10:12:00</td>
    </tr>
    <tr>
      <th>7</th>
      <td>18102.0</td>
      <td>64124</td>
      <td>2010-12-07 16:42:00</td>
      <td>2011-12-09 11:50:00</td>
    </tr>
    <tr>
      <th>8</th>
      <td>13694.0</td>
      <td>63312</td>
      <td>2010-12-01 12:12:00</td>
      <td>2011-12-06 09:32:00</td>
    </tr>
    <tr>
      <th>9</th>
      <td>14298.0</td>
      <td>58343</td>
      <td>2010-12-14 12:59:00</td>
      <td>2011-12-01 13:12:00</td>
    </tr>
  </tbody>
</table>
</div>



The table above shows the top 10 users with the highest total quantity. The largest total quantity is about 200,000, which is more than three times that of about 60,000 in the 10th place. When looking at the period of ordering as well, customer 12346 ordered 70,000 quantities a day. That is, customer 14646 has the largest total quantity without considering the period, and 12346 has the largest total quantity considering the period.

### (Q2 - 3)

Let's consider the number of invoices and the total quantity together.


```python
df_total_invoice_quantity = pd.DataFrame(df_merged.groupby("CustomerID").InvoiceNo.nunique().reset_index().rename({"InvoiceNo" : "total_invoice_number"}, axis = 1)) \
                                .merge(df_merged.groupby("CustomerID").Quantity.sum().reset_index().rename({"Quantity" : "total_quantity"}, axis = 1))
```


```python
df_total_invoice_quantity.sort_values("total_invoice_number", ascending = False).head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CustomerID</th>
      <th>total_invoice_number</th>
      <th>total_quantity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>326</th>
      <td>12748.0</td>
      <td>210</td>
      <td>25748</td>
    </tr>
    <tr>
      <th>1880</th>
      <td>14911.0</td>
      <td>201</td>
      <td>80515</td>
    </tr>
    <tr>
      <th>4011</th>
      <td>17841.0</td>
      <td>124</td>
      <td>23071</td>
    </tr>
    <tr>
      <th>562</th>
      <td>13089.0</td>
      <td>97</td>
      <td>31070</td>
    </tr>
    <tr>
      <th>1662</th>
      <td>14606.0</td>
      <td>93</td>
      <td>6224</td>
    </tr>
    <tr>
      <th>2177</th>
      <td>15311.0</td>
      <td>91</td>
      <td>38194</td>
    </tr>
    <tr>
      <th>481</th>
      <td>12971.0</td>
      <td>86</td>
      <td>9289</td>
    </tr>
    <tr>
      <th>1690</th>
      <td>14646.0</td>
      <td>74</td>
      <td>197491</td>
    </tr>
    <tr>
      <th>2703</th>
      <td>16029.0</td>
      <td>63</td>
      <td>40208</td>
    </tr>
    <tr>
      <th>796</th>
      <td>13408.0</td>
      <td>62</td>
      <td>16232</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_total_invoice_quantity[["total_invoice_number","total_quantity"]].corr()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_invoice_number</th>
      <th>total_quantity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>total_invoice_number</th>
      <td>1.000000</td>
      <td>0.558005</td>
    </tr>
    <tr>
      <th>total_quantity</th>
      <td>0.558005</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



First, if you check the correlation between the total invoice number and total quantity for all customers, it is about 0.5. The correlation coefficient is a statistic that indicates how linear two variables are and has a value between -1 and 1. A positive value indicates a positive linear relationship, and a negative value indicates a negative linear relationship. The closer the absolute value is to 1, the stronger the linear relationship is. Since the correlation is about 0.5, it can be seen that the total invoice number and total quantity show a positive linear relationship to some extent.


```python
df_total_invoice_quantity[["total_invoice_number","total_quantity"]].sort_values("total_invoice_number", ascending = False).head(10).corr()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_invoice_number</th>
      <th>total_quantity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>total_invoice_number</th>
      <td>1.000000</td>
      <td>-0.038673</td>
    </tr>
    <tr>
      <th>total_quantity</th>
      <td>-0.038673</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



However, when only the top 10 people based on the invoice number were analyzed, it can be seen that the correlation between the total invoice number and the total quantity is rather low at -0.03.


```python
sns.scatterplot(x = "total_invoice_number", y = "total_quantity", data = df_total_invoice_quantity[["total_invoice_number","total_quantity"]].sort_values("total_invoice_number", ascending = False).head(10),)
```




    <AxesSubplot:xlabel='total_invoice_number', ylabel='total_quantity'>




    
![png](/assets/images/coursework/SI618/hw2/hw2_upload_134_1.png)
    


Even if you look at the total invoice number and total quantity of the top 10 people as a plot, you can see that there is almost no linear relationship between the two variables.

## <span style="color:magenta"> Q3. [10 points] Item Analysis </span>
1. What is the average item-unit price? 
1. What % of items are under $25?
1. Generate a histogram of the unit prices. Select reasonable min/max values for the x-axis. Why did you pick those values? What do you notice about the histogram? 

 ### (Q3 - 1) & (Q3 - 3)


```python
df_item.UnitPrice.mean()
```




    6.905277886977952



In simple calculations, the average unit price of an item is about 7 sterling.


```python
df_item[df_item.UnitPrice == 0].shape
```




    (215, 3)




```python
df_item_positive_price = df_item[df_item.UnitPrice > 0]
df_item_positive_price.UnitPrice.mean()
```




    7.290397146562974



However, about 5% of the items in the item data have a unit price of 0. So, if you exclude items with a unit price of 0, the average unit price is 7.2 sterling.


```python
df_item_positive_price.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>UnitPrice</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>3855.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>7.290397</td>
    </tr>
    <tr>
      <th>std</th>
      <td>178.548626</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.001000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.250000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2.510000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.950000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>11062.060000</td>
    </tr>
  </tbody>
</table>
</div>



Also, since the average is greatly affected by outliers, it is necessary to check whether there are outliers when calculating the average. Looking at the table above, about 75% of items are lower than 5 sterling, but the average price we found above was 7.2 sterling. This is because there is an extreme value in the price, such as the max value of 11062.


```python
sns.distplot(np.log(df_item_positive_price.UnitPrice))
```

    /opt/anaconda3/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
      warnings.warn(msg, FutureWarning)





    <AxesSubplot:xlabel='UnitPrice', ylabel='Density'>




    
![png](/assets/images/coursework/SI618/hw2/hw2_upload_145_2.png)
    


If you log-transform the unit price, you can confirm that it roughly follows a normal distribution. Therefore, let's reduce the influence of outliers by using only about 95% of the data within 2 standard deviations from the average in the log unit price.


```python
lower_bound = np.log(df_item_positive_price.UnitPrice).describe()[1] - (2 * np.log(df_item_positive_price.UnitPrice).describe()[2])
lower_bound
```




    -1.1411714381940192




```python
upper_bound = np.log(df_item_positive_price.UnitPrice).describe()[1] + (2 * np.log(df_item_positive_price.UnitPrice).describe()[2])
upper_bound
```




    2.9566302011417886




```python
df_item_positive_price_except_outlier = df_item_positive_price[(np.log(df_item_positive_price.UnitPrice) > lower_bound) & (np.log(df_item_positive_price.UnitPrice) < upper_bound)]
df_item_positive_price_except_outlier.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>UnitPrice</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>3716.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.580312</td>
    </tr>
    <tr>
      <th>std</th>
      <td>3.244735</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.320000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.250000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2.510000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.250000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>19.130000</td>
    </tr>
  </tbody>
</table>
</div>




```python
sns.distplot(df_item_positive_price_except_outlier.UnitPrice)
```

    /opt/anaconda3/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
      warnings.warn(msg, FutureWarning)





    <AxesSubplot:xlabel='UnitPrice', ylabel='Density'>




    
![png](/assets/images/coursework/SI618/hw2/hw2_upload_150_2.png)
    


When looking at only 95% of data excluding outliers, the minimum value of unit price is 0.3 sterling and the maximum value is 19 sterling, which is somewhat reasonable. The average item-unit price is 3.58 sterling with this reduced data.

### (Q3 - 2)

To find items that are under 25$, we have to convert our sterling unit price to dollar unit price. I will apply the exchange rate between sterling and dollar as 1:1.3.


```python
df_item["unit_price_dollar"] = df_item.UnitPrice * 1.13
df_item
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
      <th>unit_price_dollar</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>85123A</td>
      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>
      <td>2.55</td>
      <td>2.8815</td>
    </tr>
    <tr>
      <th>1</th>
      <td>71053</td>
      <td>WHITE METAL LANTERN</td>
      <td>3.39</td>
      <td>3.8307</td>
    </tr>
    <tr>
      <th>2</th>
      <td>84406B</td>
      <td>CREAM CUPID HEARTS COAT HANGER</td>
      <td>2.75</td>
      <td>3.1075</td>
    </tr>
    <tr>
      <th>3</th>
      <td>84029G</td>
      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>
      <td>3.39</td>
      <td>3.8307</td>
    </tr>
    <tr>
      <th>4</th>
      <td>84029E</td>
      <td>RED WOOLLY HOTTIE WHITE HEART.</td>
      <td>3.39</td>
      <td>3.8307</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4065</th>
      <td>85179a</td>
      <td>GREEN BITTY LIGHT CHAIN</td>
      <td>2.46</td>
      <td>2.7798</td>
    </tr>
    <tr>
      <th>4066</th>
      <td>23617</td>
      <td>SET 10 CARDS SWIRLY XMAS TREE 17104</td>
      <td>2.91</td>
      <td>3.2883</td>
    </tr>
    <tr>
      <th>4067</th>
      <td>90214U</td>
      <td>LETTER "U" BLING KEY RING</td>
      <td>0.29</td>
      <td>0.3277</td>
    </tr>
    <tr>
      <th>4068</th>
      <td>47591b</td>
      <td>SCOTTIES CHILDRENS APRON</td>
      <td>4.13</td>
      <td>4.6669</td>
    </tr>
    <tr>
      <th>4069</th>
      <td>23843</td>
      <td>PAPER CRAFT , LITTLE BIRDIE</td>
      <td>2.08</td>
      <td>2.3504</td>
    </tr>
  </tbody>
</table>
<p>4070 rows × 4 columns</p>
</div>




```python
np.sum(df_item.unit_price_dollar < 25) / len(df_item.unit_price_dollar < 25)
```




    0.9867321867321868



Including zero-price items, about 98.6% of items are under $25. 


```python
np.sum(df_item.loc[df_item_positive_price.index].unit_price_dollar < 25) / len(df_item.loc[df_item_positive_price.index].unit_price_dollar < 25)
```




    0.9859922178988327



Excluding zero-price items, about 93.3% of items are under $25.


```python
np.sum(df_item.loc[df_item_positive_price_except_outlier.index].unit_price_dollar < 25) / len(df_item.loc[df_item_positive_price_except_outlier.index].unit_price_dollar < 25)
```




    1.0



Excluding all outliers as above, all items are under $25.

## <span style="color:magenta"> Q4. [25 points] Order Trends </span>
1. What are the top 10 most ordered items? Describe them. Do you see any trends?  
1. What are the top 5 invoices that generated the most revenue? (Revenue is calculated by "marking up" the unit price by 25%.) 
1. Do the top 5 invoices contain any of the top 10 most ordered items?

_Hint: When calculating the revenue we suggest adding a new column on the dataframe._

### (Q4 - 1)

There can be several different ways to measure the most ordered items. If it is measured based on quantity, rank can be affected in cases where a particular item is traded a lot in one transaction. So I will measure most ordered items by invoice count. Also, since we only need to measure when items are clearly ordered, we will exclude cases where quantity is negative.


```python
df_merged_positive_quantity = df_merged[df_merged.Quantity > 0]
```


```python
most_ordered_items = df_merged_positive_quantity.groupby("StockCode").InvoiceNo.nunique().sort_values(ascending = False).head(10).reset_index().rename({"InvoiceNo" : "invoice_count"}, axis = 1) \
                     .merge(df_item[["StockCode", "Description"]], on = "StockCode", how = "left")
most_ordered_items
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>StockCode</th>
      <th>invoice_count</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>85123A</td>
      <td>2203</td>
      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>
    </tr>
    <tr>
      <th>1</th>
      <td>85099B</td>
      <td>2092</td>
      <td>JUMBO BAG RED RETROSPOT</td>
    </tr>
    <tr>
      <th>2</th>
      <td>22423</td>
      <td>1989</td>
      <td>REGENCY CAKESTAND 3 TIER</td>
    </tr>
    <tr>
      <th>3</th>
      <td>47566</td>
      <td>1686</td>
      <td>PARTY BUNTING</td>
    </tr>
    <tr>
      <th>4</th>
      <td>20725</td>
      <td>1565</td>
      <td>LUNCH BAG RED RETROSPOT</td>
    </tr>
    <tr>
      <th>5</th>
      <td>84879</td>
      <td>1455</td>
      <td>ASSORTED COLOUR BIRD ORNAMENT</td>
    </tr>
    <tr>
      <th>6</th>
      <td>22197</td>
      <td>1392</td>
      <td>SMALL POPCORN HOLDER</td>
    </tr>
    <tr>
      <th>7</th>
      <td>22720</td>
      <td>1387</td>
      <td>SET OF 3 CAKE TINS PANTRY DESIGN</td>
    </tr>
    <tr>
      <th>8</th>
      <td>21212</td>
      <td>1320</td>
      <td>PACK OF 72 RETROSPOT CAKE CASES</td>
    </tr>
    <tr>
      <th>9</th>
      <td>22383</td>
      <td>1285</td>
      <td>LUNCH BAG SUKI  DESIGN</td>
    </tr>
  </tbody>
</table>
</div>



The above table shows the top 10 most ordered items. Overall, party-related items seem to occupy the upper ranks. The 3rd, 8th, and 9th places were cake-related items, and there were a total of 4700 invoices. The 1st, 4th, 6th, and 7th places were party-related decorations, and there were a total of 6700 invoices. The 2nd, 5th, and 10th places were bag types, and there were a total of 4900 invoices. 

### (Q4 - 2)

Revenue is calculated by "marking up" the unit price by 25%. So, let's make a new revenue column calculated by unit price * 1.25 * quantity.


```python
df_merged_positive_quantity["revenue"] = df_merged_positive_quantity.UnitPrice * 1.25 * df_merged_positive_quantity.Quantity
df_merged_positive_quantity
```

    /var/folders/kb/9bgdwxjn0b751yc9w59v1ll00000gn/T/ipykernel_53930/1210467572.py:1: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      df_merged_positive_quantity["revenue"] = df_merged_positive_quantity.UnitPrice * 1.25 * df_merged_positive_quantity.Quantity





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
      <th>Quantity</th>
      <th>revenue</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>85123A</td>
      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>
      <td>2.55</td>
      <td>6</td>
      <td>19.1250</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>71053</td>
      <td>WHITE METAL LANTERN</td>
      <td>3.39</td>
      <td>6</td>
      <td>25.4250</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84406B</td>
      <td>CREAM CUPID HEARTS COAT HANGER</td>
      <td>2.75</td>
      <td>8</td>
      <td>27.5000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84029G</td>
      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>
      <td>3.39</td>
      <td>6</td>
      <td>25.4250</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84029E</td>
      <td>RED WOOLLY HOTTIE WHITE HEART.</td>
      <td>3.39</td>
      <td>6</td>
      <td>25.4250</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>532616</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>22613</td>
      <td>PACK OF 20 SPACEBOY NAPKINS</td>
      <td>1.66</td>
      <td>12</td>
      <td>24.9000</td>
    </tr>
    <tr>
      <th>532617</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>22899</td>
      <td>CHILDREN'S APRON DOLLY GIRL</td>
      <td>2.10</td>
      <td>6</td>
      <td>15.7500</td>
    </tr>
    <tr>
      <th>532618</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>23254</td>
      <td>CHILDRENS CUTLERY DOLLY GIRL</td>
      <td>4.15</td>
      <td>4</td>
      <td>20.7500</td>
    </tr>
    <tr>
      <th>532619</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>23255</td>
      <td>CHILDRENS CUTLERY CIRCUS PARADE</td>
      <td>4.15</td>
      <td>4</td>
      <td>20.7500</td>
    </tr>
    <tr>
      <th>532620</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>22138</td>
      <td>BAKING SET 9 PIECE RETROSPOT</td>
      <td>4.95</td>
      <td>3</td>
      <td>18.5625</td>
    </tr>
  </tbody>
</table>
<p>531285 rows × 9 columns</p>
</div>




```python
invoice_top_revenue = np.round(df_merged_positive_quantity.groupby("InvoiceNo").sum()[["revenue", "Quantity"]].sort_values("revenue", ascending = False).head(5)) \
                          .merge(df_merged_positive_quantity.groupby("InvoiceNo").nunique().StockCode, on = "InvoiceNo", how = "left") \
                          .merge(df_invoice_shipped[["InvoiceNo", "Country", "CustomerID", "InvoiceDate"]], on = "InvoiceNo", how = "left") \
                          .rename({"revenue" : "total_revenue", "Quantity" : "total_quantity", "StockCode" : "unique_stockcode_count"}, axis = 1)
invoice_top_revenue
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>total_revenue</th>
      <th>total_quantity</th>
      <th>unique_stockcode_count</th>
      <th>Country</th>
      <th>CustomerID</th>
      <th>InvoiceDate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>547966</td>
      <td>712212.0</td>
      <td>1000</td>
      <td>1</td>
      <td>United Kingdom</td>
      <td>NaN</td>
      <td>2011-03-28 15:49:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>581483</td>
      <td>210587.0</td>
      <td>80995</td>
      <td>1</td>
      <td>United Kingdom</td>
      <td>16446.0</td>
      <td>2011-12-09 09:15:00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>541431</td>
      <td>96480.0</td>
      <td>74215</td>
      <td>1</td>
      <td>United Kingdom</td>
      <td>12346.0</td>
      <td>2011-01-18 10:01:00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>556255</td>
      <td>37305.0</td>
      <td>3600</td>
      <td>12</td>
      <td>United Kingdom</td>
      <td>18102.0</td>
      <td>2011-06-09 17:27:00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>556917</td>
      <td>34546.0</td>
      <td>15049</td>
      <td>138</td>
      <td>Australia</td>
      <td>12415.0</td>
      <td>2011-06-15 13:37:00</td>
    </tr>
  </tbody>
</table>
</div>



The above table shows the top 5 invoices that generated the most revenue in sterling. 1st invoice generated revenue of 710,000 sterling, which is three times higher than the second invoice's revenue of 210,000 sterling. The trades that yielded the most revenue were only 1000 quantities of only one type. Compared to other invoices that traded 3,000, 10,000, 70,000, and 80,000 quantities, it can be seen that the largest profit was made with a very small quantity. Of the total of 5 invoices, only 1 was ordered from Australia and the remaining 4 were all ordered from the United Kingdom. And all 4 invoices were made in the first half of 2011, and only one invoice was made at the end of 2011. 

### (Q4 - 3) 


```python
most_ordered_items["is_most_ordered"] = 1
```


```python
invoice_top_revenue_with_item = df_merged_positive_quantity[["InvoiceNo","StockCode"]].merge(invoice_top_revenue["InvoiceNo"], on = "InvoiceNo", how = "inner") \
                                    .merge(most_ordered_items[["StockCode", "Description", "is_most_ordered"]], on = "StockCode", how = "left").fillna(0)
invoice_top_revenue_with_item
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>StockCode</th>
      <th>Description</th>
      <th>is_most_ordered</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>541431</td>
      <td>23166</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>547966</td>
      <td>DOT</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>556255</td>
      <td>48138</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>556255</td>
      <td>48173C</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>556255</td>
      <td>48188</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>148</th>
      <td>556917</td>
      <td>22364</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>149</th>
      <td>556917</td>
      <td>22363</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>150</th>
      <td>556917</td>
      <td>21115</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>151</th>
      <td>556917</td>
      <td>22308</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>152</th>
      <td>581483</td>
      <td>23843</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>153 rows × 4 columns</p>
</div>




```python
invoice_top_revenue_with_item[invoice_top_revenue_with_item.is_most_ordered == 1] 
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>StockCode</th>
      <th>Description</th>
      <th>is_most_ordered</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>61</th>
      <td>556917</td>
      <td>20725</td>
      <td>LUNCH BAG RED RETROSPOT</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>89</th>
      <td>556917</td>
      <td>85099B</td>
      <td>JUMBO BAG RED RETROSPOT</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>100</th>
      <td>556917</td>
      <td>22423</td>
      <td>REGENCY CAKESTAND 3 TIER</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>107</th>
      <td>556917</td>
      <td>21212</td>
      <td>PACK OF 72 RETROSPOT CAKE CASES</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>110</th>
      <td>556917</td>
      <td>22720</td>
      <td>SET OF 3 CAKE TINS PANTRY DESIGN</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>



is_most_ordered column has a value of 1 if each item in each invoice is the top 10 most ordered items. Looking at the table above, only the "556917" invoice of the top 5 invoices contains 5 items from the top 10 most ordered items. This invoice contains all cake-related items and two bag-related items of the top 10 most ordered items.

## <span style="color:magenta"> Q5. [30 points] Customer Analysis </span>
1. Classify customers into segments based on the total revenue they have generated for the company.
 * low value: less than \$1500  
 * medium value: between 1500 and 8000 dollars
 * high value: greater than \$8000
1. How many customers are in each segment? 
1. Using the pivot table function, create a table that displays the average order quantity of each stock code for a given segment.
1. Are the items with the highest average order quantity generally the same across segments? Explain your reasoning. 
1. Choose three items and discuss any trends/differences you notice across the three segments.

_Hint: When calculating the segment, we suggest constructing a new dataframe as an intermediary step with the columns: CustomerID, Revenue, Segment._

Since the customer segments are divided based on revenue calculated in dollars, let's convert revenue into dollars.


```python
df_merged_positive_quantity["revenue_dollar"] = df_merged_positive_quantity.revenue * 1.3
df_merged_positive_quantity.head()
```

    /var/folders/kb/9bgdwxjn0b751yc9w59v1ll00000gn/T/ipykernel_53930/3486501612.py:1: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      df_merged_positive_quantity["revenue_dollar"] = df_merged_positive_quantity.revenue * 1.3





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
      <th>Quantity</th>
      <th>revenue</th>
      <th>revenue_dollar</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>85123A</td>
      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>
      <td>2.55</td>
      <td>6</td>
      <td>19.125</td>
      <td>24.8625</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>71053</td>
      <td>WHITE METAL LANTERN</td>
      <td>3.39</td>
      <td>6</td>
      <td>25.425</td>
      <td>33.0525</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84406B</td>
      <td>CREAM CUPID HEARTS COAT HANGER</td>
      <td>2.75</td>
      <td>8</td>
      <td>27.500</td>
      <td>35.7500</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84029G</td>
      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>
      <td>3.39</td>
      <td>6</td>
      <td>25.425</td>
      <td>33.0525</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84029E</td>
      <td>RED WOOLLY HOTTIE WHITE HEART.</td>
      <td>3.39</td>
      <td>6</td>
      <td>25.425</td>
      <td>33.0525</td>
    </tr>
  </tbody>
</table>
</div>




```python
customer_revenue = df_merged_positive_quantity.groupby("CustomerID").sum().revenue_dollar.reset_index().rename({"revenue_dollar" : "total_revenue_dollar"}, axis = 1)
customer_revenue
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CustomerID</th>
      <th>total_revenue_dollar</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12346.0</td>
      <td>125423.35000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>12347.0</td>
      <td>8837.46500</td>
    </tr>
    <tr>
      <th>2</th>
      <td>12348.0</td>
      <td>2909.01000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>12349.0</td>
      <td>3131.31000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>12350.0</td>
      <td>663.06500</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4334</th>
      <td>18280.0</td>
      <td>412.19750</td>
    </tr>
    <tr>
      <th>4335</th>
      <td>18281.0</td>
      <td>109.65500</td>
    </tr>
    <tr>
      <th>4336</th>
      <td>18282.0</td>
      <td>377.60125</td>
    </tr>
    <tr>
      <th>4337</th>
      <td>18283.0</td>
      <td>3451.56500</td>
    </tr>
    <tr>
      <th>4338</th>
      <td>18287.0</td>
      <td>4446.48750</td>
    </tr>
  </tbody>
</table>
<p>4339 rows × 2 columns</p>
</div>




```python
low_segment_mask = customer_revenue.total_revenue_dollar < 1500
medium_segment_mask = (customer_revenue.total_revenue_dollar >= 1500) & (customer_revenue.total_revenue_dollar < 8000)
high_segment_mask = customer_revenue.total_revenue_dollar >= 8000
```


```python
customer_revenue.loc[low_segment_mask, "revenue_segment"] = "low"
customer_revenue.loc[medium_segment_mask, "revenue_segment"] = "medium"
customer_revenue.loc[high_segment_mask, "revenue_segment"] = "high"
```


```python
customer_revenue
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CustomerID</th>
      <th>total_revenue_dollar</th>
      <th>revenue_segment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12346.0</td>
      <td>125423.35000</td>
      <td>high</td>
    </tr>
    <tr>
      <th>1</th>
      <td>12347.0</td>
      <td>8837.46500</td>
      <td>high</td>
    </tr>
    <tr>
      <th>2</th>
      <td>12348.0</td>
      <td>2909.01000</td>
      <td>medium</td>
    </tr>
    <tr>
      <th>3</th>
      <td>12349.0</td>
      <td>3131.31000</td>
      <td>medium</td>
    </tr>
    <tr>
      <th>4</th>
      <td>12350.0</td>
      <td>663.06500</td>
      <td>low</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4334</th>
      <td>18280.0</td>
      <td>412.19750</td>
      <td>low</td>
    </tr>
    <tr>
      <th>4335</th>
      <td>18281.0</td>
      <td>109.65500</td>
      <td>low</td>
    </tr>
    <tr>
      <th>4336</th>
      <td>18282.0</td>
      <td>377.60125</td>
      <td>low</td>
    </tr>
    <tr>
      <th>4337</th>
      <td>18283.0</td>
      <td>3451.56500</td>
      <td>medium</td>
    </tr>
    <tr>
      <th>4338</th>
      <td>18287.0</td>
      <td>4446.48750</td>
      <td>medium</td>
    </tr>
  </tbody>
</table>
<p>4339 rows × 3 columns</p>
</div>



Based on the criteria above, 3 segments(high, medium, and low) were created.

### (Q5 - 1)


```python
customer_revenue.groupby("revenue_segment").count().CustomerID.reset_index() \
    .merge(round(customer_revenue.groupby("revenue_segment").count().CustomerID / np.sum(customer_revenue.groupby("revenue_segment").count().CustomerID) * 100, 1), on = "revenue_segment", how = "left") \
    .rename({"CustomerID_x" : "total_customer_count", "CustomerID_y" : "total_customer_count_ratio"}, axis = 1) \
    .loc[[0, 2, 1]]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>revenue_segment</th>
      <th>total_customer_count</th>
      <th>total_customer_count_ratio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>high</td>
      <td>356</td>
      <td>8.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>medium</td>
      <td>1656</td>
      <td>38.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>low</td>
      <td>2327</td>
      <td>53.6</td>
    </tr>
  </tbody>
</table>
</div>



There are 2327 customers in the low segment which is about 54% of the total customers. About 38% of total customers, or 1656, belong to the medium group, and about 8%, or 356 customers, belong to the high group.

### (Q5 - 2) 


```python
df_merged_positive_quantity = df_merged_positive_quantity.merge(customer_revenue, on = "CustomerID", how = "left")
df_merged_positive_quantity
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
      <th>Quantity</th>
      <th>revenue</th>
      <th>revenue_dollar</th>
      <th>total_revenue_dollar</th>
      <th>revenue_segment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>85123A</td>
      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>
      <td>2.55</td>
      <td>6</td>
      <td>19.1250</td>
      <td>24.86250</td>
      <td>8821.16625</td>
      <td>high</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>71053</td>
      <td>WHITE METAL LANTERN</td>
      <td>3.39</td>
      <td>6</td>
      <td>25.4250</td>
      <td>33.05250</td>
      <td>8821.16625</td>
      <td>high</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84406B</td>
      <td>CREAM CUPID HEARTS COAT HANGER</td>
      <td>2.75</td>
      <td>8</td>
      <td>27.5000</td>
      <td>35.75000</td>
      <td>8821.16625</td>
      <td>high</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84029G</td>
      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>
      <td>3.39</td>
      <td>6</td>
      <td>25.4250</td>
      <td>33.05250</td>
      <td>8821.16625</td>
      <td>high</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84029E</td>
      <td>RED WOOLLY HOTTIE WHITE HEART.</td>
      <td>3.39</td>
      <td>6</td>
      <td>25.4250</td>
      <td>33.05250</td>
      <td>8821.16625</td>
      <td>high</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>531280</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>22613</td>
      <td>PACK OF 20 SPACEBOY NAPKINS</td>
      <td>1.66</td>
      <td>12</td>
      <td>24.9000</td>
      <td>32.37000</td>
      <td>1568.79125</td>
      <td>medium</td>
    </tr>
    <tr>
      <th>531281</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>22899</td>
      <td>CHILDREN'S APRON DOLLY GIRL</td>
      <td>2.10</td>
      <td>6</td>
      <td>15.7500</td>
      <td>20.47500</td>
      <td>1568.79125</td>
      <td>medium</td>
    </tr>
    <tr>
      <th>531282</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>23254</td>
      <td>CHILDRENS CUTLERY DOLLY GIRL</td>
      <td>4.15</td>
      <td>4</td>
      <td>20.7500</td>
      <td>26.97500</td>
      <td>1568.79125</td>
      <td>medium</td>
    </tr>
    <tr>
      <th>531283</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>23255</td>
      <td>CHILDRENS CUTLERY CIRCUS PARADE</td>
      <td>4.15</td>
      <td>4</td>
      <td>20.7500</td>
      <td>26.97500</td>
      <td>1568.79125</td>
      <td>medium</td>
    </tr>
    <tr>
      <th>531284</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>22138</td>
      <td>BAKING SET 9 PIECE RETROSPOT</td>
      <td>4.95</td>
      <td>3</td>
      <td>18.5625</td>
      <td>24.13125</td>
      <td>1568.79125</td>
      <td>medium</td>
    </tr>
  </tbody>
</table>
<p>531285 rows × 12 columns</p>
</div>



First, the customer segments obtained above were merged into our merged table.


```python
df_merged_positive_quantity.Quantity.describe()
```




    count    531285.000000
    mean         10.655262
    std         156.830323
    min           1.000000
    25%           1.000000
    50%           3.000000
    75%          10.000000
    max       80995.000000
    Name: Quantity, dtype: float64



Looking at the distribution of quantity, it can be seen that there are outliers with a max value of 80995 while about 75% is less than 10. The average quantile we want to find is greatly affected by outliers, so we will calculate the average value excluding these outliers. The minimum value of a quantity is 1, which cannot be regarded as an outlier, so only the outliers toward the maximum value will be removed.


```python
percentile_99 = np.percentile(df_merged_positive_quantity.Quantity, 99.5)
percentile_99
```




    168.0



99.5th quantile quantity value is 168 and it is a reasonable value for quantity. Therefore, the analysis will be performed using only 99.5% of the data to reduce the influence of quantity outliers.


```python
df_merged_positive_quantity_except_outlier = df_merged_positive_quantity[df_merged_positive_quantity.Quantity <= percentile_99]
```


```python
segment_stockcode_average_quantity = df_merged_positive_quantity_except_outlier[["CustomerID", "revenue_segment", "InvoiceNo", "StockCode", "Quantity"]] \
                                    .pivot_table(index = "revenue_segment", columns = "StockCode", values = "Quantity", aggfunc = np.mean).fillna(0)
segment_stockcode_average_quantity
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>StockCode</th>
      <th>10002</th>
      <th>10080</th>
      <th>10120</th>
      <th>10123C</th>
      <th>10124A</th>
      <th>10124G</th>
      <th>10125</th>
      <th>10133</th>
      <th>10135</th>
      <th>11001</th>
      <th>...</th>
      <th>90214V</th>
      <th>90214W</th>
      <th>90214Y</th>
      <th>90214Z</th>
      <th>BANK CHARGES</th>
      <th>C2</th>
      <th>DOT</th>
      <th>M</th>
      <th>PADS</th>
      <th>POST</th>
    </tr>
    <tr>
      <th>revenue_segment</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>high</th>
      <td>27.450000</td>
      <td>12.5000</td>
      <td>7.714286</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>36.857143</td>
      <td>14.424242</td>
      <td>18.342857</td>
      <td>15.368421</td>
      <td>...</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0000</td>
      <td>1.0</td>
      <td>7.089888</td>
      <td>1.0</td>
      <td>3.518519</td>
    </tr>
    <tr>
      <th>low</th>
      <td>6.000000</td>
      <td>24.0000</td>
      <td>5.500000</td>
      <td>2.0</td>
      <td>3.5</td>
      <td>4.5</td>
      <td>12.750000</td>
      <td>17.285714</td>
      <td>14.571429</td>
      <td>11.692308</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>48.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0625</td>
      <td>0.0</td>
      <td>6.040000</td>
      <td>1.0</td>
      <td>1.839286</td>
    </tr>
    <tr>
      <th>medium</th>
      <td>10.347826</td>
      <td>13.5625</td>
      <td>6.461538</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>9.645161</td>
      <td>22.071429</td>
      <td>12.070175</td>
      <td>13.677419</td>
      <td>...</td>
      <td>12.0</td>
      <td>12.0</td>
      <td>12.0</td>
      <td>12.0</td>
      <td>1.0</td>
      <td>1.0000</td>
      <td>0.0</td>
      <td>6.184874</td>
      <td>1.0</td>
      <td>2.678119</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 3663 columns</p>
</div>



The above table is the pivot table that displays the average order quantity of each stock code for a given segment. Since there are over 3000 stock codes, it is difficult to identify them at a glance. Let's look at only 3 stock codes with a high average order quantity for each segment.


```python
segment_stockcode_average_quantity_unstacked = segment_stockcode_average_quantity.unstack().reset_index() \
                                                   .rename({0 : "average_quantity"}, axis = 1)[["revenue_segment","StockCode","average_quantity"]] \
                                                   .sort_values(["revenue_segment", "average_quantity"], ascending = False)  
segment_stockcode_average_quantity_unstacked
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>revenue_segment</th>
      <th>StockCode</th>
      <th>average_quantity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>101</th>
      <td>medium</td>
      <td>16033</td>
      <td>120.000000</td>
    </tr>
    <tr>
      <th>107</th>
      <td>medium</td>
      <td>16045</td>
      <td>100.000000</td>
    </tr>
    <tr>
      <th>284</th>
      <td>medium</td>
      <td>17084R</td>
      <td>79.200000</td>
    </tr>
    <tr>
      <th>7202</th>
      <td>medium</td>
      <td>35001W</td>
      <td>78.000000</td>
    </tr>
    <tr>
      <th>224</th>
      <td>medium</td>
      <td>16259</td>
      <td>74.714286</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10941</th>
      <td>high</td>
      <td>90214O</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>10953</th>
      <td>high</td>
      <td>90214T</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>10956</th>
      <td>high</td>
      <td>90214U</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>10962</th>
      <td>high</td>
      <td>90214W</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>10968</th>
      <td>high</td>
      <td>90214Z</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
<p>10989 rows × 3 columns</p>
</div>




```python
segment_stockcode_average_quantity_unstacked["average_quantity_rank"] = segment_stockcode_average_quantity_unstacked.groupby("revenue_segment").cumcount() + 1
segment_stockcode_average_quantity_unstacked = segment_stockcode_average_quantity_unstacked.merge(df_item[["StockCode","Description"]], on = "StockCode", how = "left")
segment_stockcode_average_quantity_unstacked[segment_stockcode_average_quantity_unstacked.average_quantity_rank <= 3] \
    .set_index(["revenue_segment", "StockCode"]).loc[["high", "medium", "low"]]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>average_quantity</th>
      <th>average_quantity_rank</th>
      <th>Description</th>
    </tr>
    <tr>
      <th>revenue_segment</th>
      <th>StockCode</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">high</th>
      <th>23440</th>
      <td>144.000000</td>
      <td>1</td>
      <td>PAINT YOUR OWN EGGS IN CRATE</td>
    </tr>
    <tr>
      <th>85025B</th>
      <td>144.000000</td>
      <td>2</td>
      <td>EAU DE NILE HEART SHAPE PHOTO FRAME</td>
    </tr>
    <tr>
      <th>75178</th>
      <td>108.250000</td>
      <td>3</td>
      <td>ASSTD COL BUTTERFLY/CRYSTAL W/CHIME</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">medium</th>
      <th>16033</th>
      <td>120.000000</td>
      <td>1</td>
      <td>MINI HIGHLIGHTER PENS</td>
    </tr>
    <tr>
      <th>16045</th>
      <td>100.000000</td>
      <td>2</td>
      <td>POPART WOODEN PENCILS ASST</td>
    </tr>
    <tr>
      <th>17084R</th>
      <td>79.200000</td>
      <td>3</td>
      <td>ASSORTED INCENSE PACK</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">low</th>
      <th>16045</th>
      <td>100.000000</td>
      <td>1</td>
      <td>POPART WOODEN PENCILS ASST</td>
    </tr>
    <tr>
      <th>16259</th>
      <td>99.666667</td>
      <td>2</td>
      <td>PIECE OF CAMO STATIONERY SET</td>
    </tr>
    <tr>
      <th>17084R</th>
      <td>96.000000</td>
      <td>3</td>
      <td>ASSORTED INCENSE PACK</td>
    </tr>
  </tbody>
</table>
</div>



The above table shows 3 stock codes with the highest average order in each revenue segment.

### (Q5 - 3) 

It can be seen that the top 3 items of the high segment are all something related to ornaments, and the top 3 items of the medium and low segments are all types of writing instruments. And especially in the medium and low segment, it can be seen that the "16045" and "17084R" two items are commonly included in the top three items. Therefore, items with the highest average order quantity are generally the same across medium and low segments and the high segment is a little bit different from the other segments.

### (Q5 - 4)

I'm trying to figure out what kind of difference or trend there are in the quantity for each segment by selecting the top 3 items that are frequently traded over several months.


```python
df_merged_positive_quantity_except_outlier["invoice_year_month"] = pd.to_datetime(df_merged_positive_quantity_except_outlier['InvoiceDate']).dt.to_period('M')
```

    /var/folders/kb/9bgdwxjn0b751yc9w59v1ll00000gn/T/ipykernel_53930/2851248984.py:1: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      df_merged_positive_quantity_except_outlier["invoice_year_month"] = pd.to_datetime(df_merged_positive_quantity_except_outlier['InvoiceDate']).dt.to_period('M')



```python
df_merged_positive_quantity_except_outlier
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>InvoiceNo</th>
      <th>InvoiceDate</th>
      <th>CustomerID</th>
      <th>Country</th>
      <th>StockCode</th>
      <th>Description</th>
      <th>UnitPrice</th>
      <th>Quantity</th>
      <th>revenue</th>
      <th>revenue_dollar</th>
      <th>total_revenue_dollar</th>
      <th>revenue_segment</th>
      <th>invoice_year_month</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>85123A</td>
      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>
      <td>2.55</td>
      <td>6</td>
      <td>19.1250</td>
      <td>24.86250</td>
      <td>8821.16625</td>
      <td>high</td>
      <td>2010-12</td>
    </tr>
    <tr>
      <th>1</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>71053</td>
      <td>WHITE METAL LANTERN</td>
      <td>3.39</td>
      <td>6</td>
      <td>25.4250</td>
      <td>33.05250</td>
      <td>8821.16625</td>
      <td>high</td>
      <td>2010-12</td>
    </tr>
    <tr>
      <th>2</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84406B</td>
      <td>CREAM CUPID HEARTS COAT HANGER</td>
      <td>2.75</td>
      <td>8</td>
      <td>27.5000</td>
      <td>35.75000</td>
      <td>8821.16625</td>
      <td>high</td>
      <td>2010-12</td>
    </tr>
    <tr>
      <th>3</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84029G</td>
      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>
      <td>3.39</td>
      <td>6</td>
      <td>25.4250</td>
      <td>33.05250</td>
      <td>8821.16625</td>
      <td>high</td>
      <td>2010-12</td>
    </tr>
    <tr>
      <th>4</th>
      <td>536365</td>
      <td>2010-12-01 08:26:00</td>
      <td>17850.0</td>
      <td>United Kingdom</td>
      <td>84029E</td>
      <td>RED WOOLLY HOTTIE WHITE HEART.</td>
      <td>3.39</td>
      <td>6</td>
      <td>25.4250</td>
      <td>33.05250</td>
      <td>8821.16625</td>
      <td>high</td>
      <td>2010-12</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>531280</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>22613</td>
      <td>PACK OF 20 SPACEBOY NAPKINS</td>
      <td>1.66</td>
      <td>12</td>
      <td>24.9000</td>
      <td>32.37000</td>
      <td>1568.79125</td>
      <td>medium</td>
      <td>2011-12</td>
    </tr>
    <tr>
      <th>531281</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>22899</td>
      <td>CHILDREN'S APRON DOLLY GIRL</td>
      <td>2.10</td>
      <td>6</td>
      <td>15.7500</td>
      <td>20.47500</td>
      <td>1568.79125</td>
      <td>medium</td>
      <td>2011-12</td>
    </tr>
    <tr>
      <th>531282</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>23254</td>
      <td>CHILDRENS CUTLERY DOLLY GIRL</td>
      <td>4.15</td>
      <td>4</td>
      <td>20.7500</td>
      <td>26.97500</td>
      <td>1568.79125</td>
      <td>medium</td>
      <td>2011-12</td>
    </tr>
    <tr>
      <th>531283</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>23255</td>
      <td>CHILDRENS CUTLERY CIRCUS PARADE</td>
      <td>4.15</td>
      <td>4</td>
      <td>20.7500</td>
      <td>26.97500</td>
      <td>1568.79125</td>
      <td>medium</td>
      <td>2011-12</td>
    </tr>
    <tr>
      <th>531284</th>
      <td>581587</td>
      <td>2011-12-09 12:50:00</td>
      <td>12680.0</td>
      <td>France</td>
      <td>22138</td>
      <td>BAKING SET 9 PIECE RETROSPOT</td>
      <td>4.95</td>
      <td>3</td>
      <td>18.5625</td>
      <td>24.13125</td>
      <td>1568.79125</td>
      <td>medium</td>
      <td>2011-12</td>
    </tr>
  </tbody>
</table>
<p>528632 rows × 13 columns</p>
</div>



A year-month column was added to check the monthly order quantity.


```python
monthly_segment_quantity = df_merged_positive_quantity_except_outlier.groupby(["StockCode","invoice_year_month", "revenue_segment"]).sum().Quantity
```


```python
monthly_segment_quantity.reset_index().groupby("StockCode").invoice_year_month.nunique().sort_values(ascending = False)
```




    StockCode
    POST      13
    21916     13
    21914     13
    21913     13
    21912     13
              ..
    90102      1
    84614A     1
    90104      1
    21777      1
    37491B     1
    Name: invoice_year_month, Length: 3663, dtype: int64



df_item

Let's analyze the "POST", "21916", "21914", which have been trading steadily for 13 months.


```python
monthly_segment_quantity_top3 = monthly_segment_quantity.loc[["POST","21916","21914"]]
```

**POST : POSTAGE**


```python
plt.figure(figsize = (15,8))

low_med_high = monthly_segment_quantity_top3.loc["POST"].reset_index().groupby("invoice_year_month")["Quantity"].sum().reset_index()
bar1 = sns.barplot(x = "invoice_year_month", y = "Quantity", data = low_med_high, color = "darkblue")

low_med = monthly_segment_quantity_top3.loc["POST"].loc[:, ["medium", "low"]].reset_index().groupby("invoice_year_month")["Quantity"].sum().reset_index()
bar2 = sns.barplot(x = "invoice_year_month", y = "Quantity", data = low_med, color = "lightblue")

low = monthly_segment_quantity_top3.loc["POST"].loc[:, "low"].reset_index().groupby("invoice_year_month")["Quantity"].sum().reset_index()
bar3 = sns.barplot(x = "invoice_year_month", y = "Quantity", data = low, color = "blue")

top_bar = mpatches.Patch(color='darkblue', label='high')
mid_bar = mpatches.Patch(color='lightblue', label='medium')
low_bar = mpatches.Patch(color='blue', label='low')
plt.legend(handles=[top_bar, mid_bar, low_bar])
```




    <matplotlib.legend.Legend at 0x7fa0309bf0d0>




    
![png](/assets/images/coursework/SI618/hw2/hw2_upload_214_1.png)
    


Except for December 2011, POST shows a steady increase in order quantity. In the case of December 2011, since all data for December has not yet been collected, the quantity may appear low, so let's check this.


```python
df_invoice_shipped.InvoiceDate.max()
```




    Timestamp('2011-12-09 12:50:00')



Since the last invoice date in our data is shown as December 9, 2011, all of the data for December 11 has not yet been collected. Therefore, from the next item, let's proceed with the analysis excluding the data for Dec.

In POST, it can be seen that a lot of orders are placed in the medium and high groups, and few orders are placed in the low group. In addition, it can be seen that the order in the medium group is increasing especially as time goes by.

**21916 : SET 12 RETRO WHITE CHALK STICKS**


```python
monthly_segment_quantity_top3.loc["21916"].drop("2011-12", axis = 0)
```




    invoice_year_month  revenue_segment
    2010-12             high                47
                        low                  5
                        medium              90
    2011-01             high                48
                        low                 24
                                          ... 
    2011-10             high               250
                        medium             112
    2011-11             high                87
                        low                 28
                        medium              98
    Name: Quantity, Length: 34, dtype: int64




```python
plt.figure(figsize = (15,8))

low_med_high = monthly_segment_quantity_top3.loc["21916"].drop("2011-12", axis = 0).reset_index().groupby("invoice_year_month")["Quantity"].sum().reset_index()
bar1 = sns.barplot(x = "invoice_year_month", y = "Quantity", data = low_med_high, color = "darkblue")

low_med = monthly_segment_quantity_top3.loc["21916"].drop("2011-12", axis = 0).loc[:, ["medium", "low"]].reset_index().groupby("invoice_year_month")["Quantity"].sum().reset_index()
bar2 = sns.barplot(x = "invoice_year_month", y = "Quantity", data = low_med, color = "lightblue")

low = monthly_segment_quantity_top3.loc["21916"].drop("2011-12", axis = 0).loc[:, "low"].reset_index().groupby("invoice_year_month")["Quantity"].sum().reset_index()
bar3 = sns.barplot(x = "invoice_year_month", y = "Quantity", data = low, color = "blue")

top_bar = mpatches.Patch(color='darkblue', label='high')
mid_bar = mpatches.Patch(color='lightblue', label='medium')
low_bar = mpatches.Patch(color='blue', label='low')
plt.legend(handles=[top_bar, mid_bar, low_bar])
```




    <matplotlib.legend.Legend at 0x7fa030c713a0>




    
![png](/assets/images/coursework/SI618/hw2/hw2_upload_221_1.png)
    


Chalk sticks showed an increasing trend from December 2010 to March 2011 but decreased exceptionally only in April 2011, and then showed a steady transaction volume. Chalk sticks also order a lot from the high and medium groups, and the low group has fewer orders.

**21914 : BLUE HARMONICA IN BOX**


```python
plt.figure(figsize = (15,8))

low_med_high = monthly_segment_quantity_top3.loc["21914"].drop("2011-12", axis = 0).reset_index().groupby("invoice_year_month")["Quantity"].sum().reset_index()
bar1 = sns.barplot(x = "invoice_year_month", y = "Quantity", data = low_med_high, color = "darkblue")

low_med = monthly_segment_quantity_top3.loc["21914"].drop("2011-12", axis = 0).loc[:, ["medium", "low"]].reset_index().groupby("invoice_year_month")["Quantity"].sum().reset_index()
bar2 = sns.barplot(x = "invoice_year_month", y = "Quantity", data = low_med, color = "lightblue")

low = monthly_segment_quantity_top3.loc["21914"].drop("2011-12", axis = 0).loc[:, "low"].reset_index().groupby("invoice_year_month")["Quantity"].sum().reset_index()
bar3 = sns.barplot(x = "invoice_year_month", y = "Quantity", data = low, color = "blue")

top_bar = mpatches.Patch(color='darkblue', label='high')
mid_bar = mpatches.Patch(color='lightblue', label='medium')
low_bar = mpatches.Patch(color='blue', label='low')
plt.legend(handles=[top_bar, mid_bar, low_bar])
```




    <matplotlib.legend.Legend at 0x7fa027d6ed90>




    
![png](/assets/images/coursework/SI618/hw2/hw2_upload_224_1.png)
    


Blue harmonica maintained its order quantity until August 2011 and then showed a sharp increase from September to November 2011. There was an increase in order quantity in all of the low, medium, and high groups.
