```python
import numpy as np 
import pandas as pd 

import sqlite3 as sql 

import matplotlib.pyplot as plt 
import seaborn as sns 
import missingno as msno 
```


```python
import warnings
warnings.filterwarnings('ignore')
```


```python
pd.set_option('display.max_columns', None)
```


```python
df_match_betting = pd.read_csv("../data/df_match_betting.csv")
```


```python
df_match_betting
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>match_api_id</th>
      <th>B365H</th>
      <th>B365D</th>
      <th>B365A</th>
      <th>BWH</th>
      <th>BWD</th>
      <th>BWA</th>
      <th>IWH</th>
      <th>IWD</th>
      <th>IWA</th>
      <th>LBH</th>
      <th>LBD</th>
      <th>LBA</th>
      <th>PSH</th>
      <th>PSD</th>
      <th>PSA</th>
      <th>WHH</th>
      <th>WHD</th>
      <th>WHA</th>
      <th>SJH</th>
      <th>SJD</th>
      <th>SJA</th>
      <th>VCH</th>
      <th>VCD</th>
      <th>VCA</th>
      <th>GBH</th>
      <th>GBD</th>
      <th>GBA</th>
      <th>BSH</th>
      <th>BSD</th>
      <th>BSA</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>492473</td>
      <td>1.73</td>
      <td>3.40</td>
      <td>5.00</td>
      <td>1.75</td>
      <td>3.35</td>
      <td>4.20</td>
      <td>1.85</td>
      <td>3.2</td>
      <td>3.5</td>
      <td>1.80</td>
      <td>3.3</td>
      <td>3.75</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.70</td>
      <td>3.30</td>
      <td>4.33</td>
      <td>1.90</td>
      <td>3.3</td>
      <td>4.00</td>
      <td>1.65</td>
      <td>3.40</td>
      <td>4.50</td>
      <td>1.78</td>
      <td>3.25</td>
      <td>4.00</td>
      <td>1.73</td>
      <td>3.40</td>
      <td>4.20</td>
    </tr>
    <tr>
      <th>1</th>
      <td>492474</td>
      <td>1.95</td>
      <td>3.20</td>
      <td>3.60</td>
      <td>1.80</td>
      <td>3.30</td>
      <td>3.95</td>
      <td>1.90</td>
      <td>3.2</td>
      <td>3.5</td>
      <td>1.90</td>
      <td>3.2</td>
      <td>3.50</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.83</td>
      <td>3.30</td>
      <td>3.60</td>
      <td>1.95</td>
      <td>3.3</td>
      <td>3.80</td>
      <td>2.00</td>
      <td>3.25</td>
      <td>3.25</td>
      <td>1.85</td>
      <td>3.25</td>
      <td>3.75</td>
      <td>1.91</td>
      <td>3.25</td>
      <td>3.60</td>
    </tr>
    <tr>
      <th>2</th>
      <td>492475</td>
      <td>2.38</td>
      <td>3.30</td>
      <td>2.75</td>
      <td>2.40</td>
      <td>3.30</td>
      <td>2.55</td>
      <td>2.60</td>
      <td>3.1</td>
      <td>2.3</td>
      <td>2.50</td>
      <td>3.2</td>
      <td>2.50</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.50</td>
      <td>3.25</td>
      <td>2.40</td>
      <td>2.63</td>
      <td>3.3</td>
      <td>2.50</td>
      <td>2.35</td>
      <td>3.25</td>
      <td>2.65</td>
      <td>2.50</td>
      <td>3.20</td>
      <td>2.50</td>
      <td>2.30</td>
      <td>3.20</td>
      <td>2.75</td>
    </tr>
    <tr>
      <th>3</th>
      <td>492476</td>
      <td>1.44</td>
      <td>3.75</td>
      <td>7.50</td>
      <td>1.40</td>
      <td>4.00</td>
      <td>6.80</td>
      <td>1.40</td>
      <td>3.9</td>
      <td>6.0</td>
      <td>1.44</td>
      <td>3.6</td>
      <td>6.50</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.44</td>
      <td>3.75</td>
      <td>6.00</td>
      <td>1.44</td>
      <td>4.0</td>
      <td>7.50</td>
      <td>1.45</td>
      <td>3.75</td>
      <td>6.50</td>
      <td>1.50</td>
      <td>3.75</td>
      <td>5.50</td>
      <td>1.44</td>
      <td>3.75</td>
      <td>6.50</td>
    </tr>
    <tr>
      <th>4</th>
      <td>492477</td>
      <td>5.00</td>
      <td>3.50</td>
      <td>1.65</td>
      <td>5.00</td>
      <td>3.50</td>
      <td>1.60</td>
      <td>4.00</td>
      <td>3.3</td>
      <td>1.7</td>
      <td>4.00</td>
      <td>3.4</td>
      <td>1.72</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.20</td>
      <td>3.40</td>
      <td>1.70</td>
      <td>4.50</td>
      <td>3.5</td>
      <td>1.73</td>
      <td>4.50</td>
      <td>3.40</td>
      <td>1.65</td>
      <td>4.50</td>
      <td>3.50</td>
      <td>1.65</td>
      <td>4.75</td>
      <td>3.30</td>
      <td>1.67</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>25974</th>
      <td>1992091</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>25975</th>
      <td>1992092</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>25976</th>
      <td>1992093</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>25977</th>
      <td>1992094</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>25978</th>
      <td>1992095</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>25979 rows Ã— 31 columns</p>
</div>



- Odds are an indication of how likely an outcome is to occur. For very likely outcomes, the odds are lower, meaning the bookmaker is expecting this outcome, and as such, a lower payout is attached to a winning bet.

- Before the last letter means betting site. There are 10 betting sites.
- Last letter
    - "H": Home win odds
    - "D": Draw odds
    - "A": Away win odds
- So there are 10 betting sites * 3 last letter = 30 betting information.

- Let's check the relation between odd and the match result.


```python
con = sql.connect("../data/database.sqlite")
org_match = pd.read_sql(
    "select * from Match", con
    )
```


```python
match_result_info = org_match[["match_api_id", "home_team_goal", "away_team_goal"]]
match_result_info["match_result"] = match_result_info.home_team_goal - match_result_info.away_team_goal
```


```python
plt.figure(figsize = (20, 20))

corr = round(df_match_betting.merge(match_result_info, how = "left", on = "match_api_id").corr(), 2)

sns.heatmap(corr, annot = True, cmap = "BrBG", vmin = -1, vmax = 1, 
            linewidths = 0.5, cbar_kws = {"shrink" : 0.5})
```




    <AxesSubplot:>




    
![png](2.3.eda_match_batting_files/2.3.eda_match_batting_10_1.png)
    


- Match result (home team goal - away team goal) have some negative correlation with home team win odd.
- Match result have some positive correlation with draw and away win odds.
- That is, it seems that odds have some information related to the match result. So let's use the odd variables as our predictors to predict the match result. 

- Also, 
    - Home team win odd has a correlation close to 1 between different sites.
    - Draw and away team win odd have a correlation close to 1 between different sites.
- That is, there are too many similar information. We need to reduce the betting related variables.


```python
msno.matrix(df_match_betting)
```




    <AxesSubplot:>




    
![png](2.3.eda_match_batting_files/2.3.eda_match_batting_13_1.png)
    



```python
df_match_betting.isna().sum().sort_values(ascending = False)
```




    PSA             14811
    PSH             14811
    PSD             14811
    BSD             11818
    BSH             11818
    BSA             11818
    GBH             11817
    GBA             11817
    GBD             11817
    SJH              8882
    SJA              8882
    SJD              8882
    IWD              3459
    IWA              3459
    IWH              3459
    LBH              3423
    LBD              3423
    LBA              3423
    VCH              3411
    VCD              3411
    VCA              3411
    WHD              3408
    WHH              3408
    WHA              3408
    BWA              3404
    BWH              3404
    BWD              3404
    B365H            3387
    B365A            3387
    B365D            3387
    match_api_id        0
    dtype: int64



- First, let's exclude the betting variables with more than 4,000 missing values.


```python
target_cols = df_match_betting.isna().sum()[df_match_betting.isna().sum() > 4000].index.values
df_match_betting = df_match_betting.drop(target_cols, axis = 1)
```


```python
msno.matrix(df_match_betting)
```




    <AxesSubplot:>




    
![png](2.3.eda_match_batting_files/2.3.eda_match_batting_17_1.png)
    


- If there is a mssing value in the B356H, then all betting variables have mssing value.


```python
df_match_betting[df_match_betting.B365H.isna()].shape
```




    (3387, 19)



- There are 3,387 matches that all betting variables have mssing values.
- Simply drop these matches.


```python
df_match_betting = df_match_betting[~df_match_betting.B365H.isna()]
```


```python
target_id = df_match_betting.match_api_id.unique()
```


```python
train_match_api_id = pd.read_csv("../data/train_match_api_id.csv")
train_match_api_id.shape
```




    (18343, 1)




```python
train_match_api_id = train_match_api_id[train_match_api_id.match_api_id.isin(target_id)]
train_match_api_id.shape
```




    (17023, 1)



- After drop the matches that don't have any betting information, train matches become 18,343 -> 17,023.


```python
test_match_api_id = pd.read_csv("../data/test_match_api_id.csv")
test_match_api_id.shape
```




    (3018, 1)




```python
test_match_api_id = test_match_api_id[test_match_api_id.match_api_id.isin(target_id)]
test_match_api_id.shape
```




    (2662, 1)



- After drop the matches that don't have any betting information, test matches become 3,018 -> 2,662.


```python
train_match_api_id.to_csv("../data/train_match_api_id.csv", index = False)
test_match_api_id.to_csv("../data/test_match_api_id.csv", index = False)
```

- If th last letter is
    - "H": Home win odds
    - "D": Draw odds
    - "A": Awa win odds
- That is, if the last letter is same, they have same information between different sites.
- So let's use summary statistics as follow:
    - last letter "H" betting odds: min, max, mean, std 
    - last letter "D" betting odds: min, max, mean, std 
    - last letter "A" betting odds: min, max, mean, std 


```python
H_odds = ["B365H", "BWH", "IWH", "LBH", "WHH", "VCH"]
D_odds = ["B365D", "BWD", "IWD", "LBD", "WHD", "VCD"]
A_odds = ["B365A", "BWA", "IWA", "LBA", "WHA", "VCA"]
```


```python
H_odds_stat = pd.DataFrame({"H_odd_min": df_match_betting[H_odds].min(axis = 1),
                            "H_odd_max": df_match_betting[H_odds].max(axis = 1),
                            "H_odd_mean": df_match_betting[H_odds].mean(axis = 1),
                            "H_odd_std": df_match_betting[H_odds].min(axis = 1)})
```


```python
D_odds_stat = pd.DataFrame({"D_odd_min": df_match_betting[D_odds].min(axis = 1),
                            "D_odd_max": df_match_betting[D_odds].max(axis = 1),
                            "D_odd_mean": df_match_betting[D_odds].mean(axis = 1),
                            "D_odd_std": df_match_betting[D_odds].min(axis = 1)})
```


```python
A_odds_stat = pd.DataFrame({"A_odd_min": df_match_betting[A_odds].min(axis = 1),
                            "A_odd_max": df_match_betting[A_odds].max(axis = 1),
                            "A_odd_mean": df_match_betting[A_odds].mean(axis = 1),
                            "A_odd_std": df_match_betting[A_odds].min(axis = 1)})
```


```python
df_match_betting_stat = pd.concat([df_match_betting.match_api_id, H_odds_stat, D_odds_stat, A_odds_stat], axis = 1)
```


```python
df_match_betting_stat
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>match_api_id</th>
      <th>H_odd_min</th>
      <th>H_odd_max</th>
      <th>H_odd_mean</th>
      <th>H_odd_std</th>
      <th>D_odd_min</th>
      <th>D_odd_max</th>
      <th>D_odd_mean</th>
      <th>D_odd_std</th>
      <th>A_odd_min</th>
      <th>A_odd_max</th>
      <th>A_odd_mean</th>
      <th>A_odd_std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>492473</td>
      <td>1.65</td>
      <td>1.85</td>
      <td>1.746667</td>
      <td>1.65</td>
      <td>3.2</td>
      <td>3.4</td>
      <td>3.325000</td>
      <td>3.2</td>
      <td>3.50</td>
      <td>5.00</td>
      <td>4.213333</td>
      <td>3.50</td>
    </tr>
    <tr>
      <th>1</th>
      <td>492474</td>
      <td>1.80</td>
      <td>2.00</td>
      <td>1.896667</td>
      <td>1.80</td>
      <td>3.2</td>
      <td>3.3</td>
      <td>3.241667</td>
      <td>3.2</td>
      <td>3.25</td>
      <td>3.95</td>
      <td>3.566667</td>
      <td>3.25</td>
    </tr>
    <tr>
      <th>2</th>
      <td>492475</td>
      <td>2.35</td>
      <td>2.60</td>
      <td>2.455000</td>
      <td>2.35</td>
      <td>3.1</td>
      <td>3.3</td>
      <td>3.233333</td>
      <td>3.1</td>
      <td>2.30</td>
      <td>2.75</td>
      <td>2.525000</td>
      <td>2.30</td>
    </tr>
    <tr>
      <th>3</th>
      <td>492476</td>
      <td>1.40</td>
      <td>1.45</td>
      <td>1.428333</td>
      <td>1.40</td>
      <td>3.6</td>
      <td>4.0</td>
      <td>3.791667</td>
      <td>3.6</td>
      <td>6.00</td>
      <td>7.50</td>
      <td>6.550000</td>
      <td>6.00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>492477</td>
      <td>4.00</td>
      <td>5.00</td>
      <td>4.450000</td>
      <td>4.00</td>
      <td>3.3</td>
      <td>3.5</td>
      <td>3.416667</td>
      <td>3.3</td>
      <td>1.60</td>
      <td>1.72</td>
      <td>1.670000</td>
      <td>1.60</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>24552</th>
      <td>2030167</td>
      <td>1.57</td>
      <td>1.65</td>
      <td>1.591667</td>
      <td>1.57</td>
      <td>3.3</td>
      <td>4.0</td>
      <td>3.758333</td>
      <td>3.3</td>
      <td>4.90</td>
      <td>7.00</td>
      <td>6.400000</td>
      <td>4.90</td>
    </tr>
    <tr>
      <th>24553</th>
      <td>2030168</td>
      <td>2.20</td>
      <td>2.38</td>
      <td>2.288333</td>
      <td>2.20</td>
      <td>3.1</td>
      <td>3.4</td>
      <td>3.208333</td>
      <td>3.1</td>
      <td>3.10</td>
      <td>3.40</td>
      <td>3.241667</td>
      <td>3.10</td>
    </tr>
    <tr>
      <th>24554</th>
      <td>2030169</td>
      <td>1.50</td>
      <td>1.60</td>
      <td>1.550000</td>
      <td>1.50</td>
      <td>3.5</td>
      <td>4.2</td>
      <td>3.900000</td>
      <td>3.5</td>
      <td>5.40</td>
      <td>7.00</td>
      <td>6.566667</td>
      <td>5.40</td>
    </tr>
    <tr>
      <th>24555</th>
      <td>2030170</td>
      <td>2.30</td>
      <td>2.40</td>
      <td>2.341667</td>
      <td>2.30</td>
      <td>3.1</td>
      <td>3.4</td>
      <td>3.250000</td>
      <td>3.1</td>
      <td>2.75</td>
      <td>3.30</td>
      <td>3.083333</td>
      <td>2.75</td>
    </tr>
    <tr>
      <th>24556</th>
      <td>2030171</td>
      <td>2.10</td>
      <td>2.30</td>
      <td>2.208333</td>
      <td>2.10</td>
      <td>3.3</td>
      <td>3.6</td>
      <td>3.433333</td>
      <td>3.3</td>
      <td>2.90</td>
      <td>3.50</td>
      <td>3.216667</td>
      <td>2.90</td>
    </tr>
  </tbody>
</table>
<p>22592 rows Ã— 13 columns</p>
</div>




```python
msno.matrix(df_match_betting_stat)
```




    <AxesSubplot:>




    
![png](2.3.eda_match_batting_files/2.3.eda_match_batting_37_1.png)
    


- Finally, we have 3 result (home win, draw, away win) * 4 summary statistics (min, max, mean, std) = 12 betting related variables.

- Save the new data frame.


```python
df_match_betting_stat.to_csv("../data/df_match_betting_stat.csv", index = False)
```

### <font color="magenta">Summary</font>

- Drop the matches that have the missing values in all betting related columns.
    - train matces: 18,343 -> 17,023
    - test matches: 3,018 -> 2,662

- Drop the betting columns that have more than 4,000 missing values. (drop 12 columns)

- Drop the betting columns that have more than 4,000 missing values. (drop 12 columns)

- If th last letter is
    - "H": Home win odds
    - "D": Draw odds
    - "A": Awa win odds
- That is, if the last letter is same, they have same information between different sites.
- So we made summary statistics as follow:
    - last letter "H" betting odds: min, max, mean, std 
    - last letter "D" betting odds: min, max, mean, std 
    - last letter "A" betting odds: min, max, mean, std 

![2.3.summary](../images/2.3.eda-summary.png)


